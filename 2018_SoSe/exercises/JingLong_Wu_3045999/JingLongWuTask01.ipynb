{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Lab Exercise 1\n",
    "Jing-Llong Wu / Mtr. Nr: 3045999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Load English Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\JingLong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\JingLong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Treebank\n",
    "treebank_tagged_sents = treebank.tagged_sents()[:1000]\n",
    "train_size = int(0.8 * len(treebank_tagged_sents))\n",
    "tb_train_sents = treebank_tagged_sents[:train_size]\n",
    "tb_test_sents = treebank_tagged_sents[train_size:]\n",
    "\n",
    "# Brown\n",
    "brown_tagged_sents = brown.tagged_sents()[:1000]\n",
    "train_size = int(0.8 * len(brown_tagged_sents))\n",
    "bn_train_sents = brown_tagged_sents[:train_size]\n",
    "bn_test_sents = brown_tagged_sents[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1]\n",
    "    }\n",
    "\n",
    "\n",
    "def untag(tagged_sentence):\n",
    "    return [w for w, t in tagged_sentence]\n",
    "\n",
    " \n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    untagrtn, featuresrtn, taggedrtn = [], [], []\n",
    "    for tagged in tagged_sentences:\n",
    "        for index in range(len(tagged)):\n",
    "            untagrtn.append(untag(tagged)[index])\n",
    "            featuresrtn.append(features(untag(tagged), index))\n",
    "            taggedrtn.append(tagged[index][1])\n",
    " \n",
    "    return untagrtn, featuresrtn, taggedrtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19933\n",
      "5251\n",
      "\n",
      "17975\n",
      "4104\n"
     ]
    }
   ],
   "source": [
    "untagrtn_train_tb, featuresrtn_train_tb, taggedrtn_train_tb = transform_to_dataset(tb_train_sents)\n",
    "untagrtn_test_tb, featuresrtn_test_tb, taggedrtn_test_tb = transform_to_dataset(tb_test_sents)\n",
    "\n",
    "untagrtn_train_train_bn, featuresrtn_train_bn, taggedrtn_train_bn = transform_to_dataset(bn_train_sents)\n",
    "untagrtn_train_test_bn, featuresrtn_test_bn, taggedrtn_test_bn = transform_to_dataset(bn_test_sents)\n",
    "\n",
    "\n",
    "print(len(featuresrtn_train_tb))\n",
    "print(len(featuresrtn_test_tb))\n",
    "print()\n",
    "print(len(featuresrtn_train_bn))\n",
    "print(len(featuresrtn_test_bn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 1.Train model based on treebank dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9099219196343553, 0.5414230019493177]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "clf.fit(featuresrtn_train_tb, taggedrtn_train_tb)\n",
    "#print(clf.score(featuresrtn_test_tb, taggedrtn_test_tb))\n",
    "\n",
    "y=[clf.score(featuresrtn_test_tb, taggedrtn_test_tb), clf.score(featuresrtn_test_bn, taggedrtn_test_bn)]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2. Pretrained model from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     C:\\Users\\JingLong\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "0.8863073700247572\n",
      "0.5896686159844055\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "\n",
    "result_tb = nltk.pos_tag(untagrtn_test_tb)\n",
    "accuracy_tb = np.mean([x[1] == y for x, y in zip(result_tb, taggedrtn_test_tb)])\n",
    "print(accuracy_tb)\n",
    "\n",
    "result_bn = nltk.pos_tag(untagrtn_train_test_bn)\n",
    "accuracy_bn = np.mean([x[1] == y for x, y in zip(result_bn, taggedrtn_test_bn)])\n",
    "print(accuracy_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3. Rule based classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12712587167009481\n",
      "0.12721386402589982\n",
      "\n",
      "0.9688456328701149\n",
      "0.7539516282612836\n",
      "\n",
      "0.9116038729744644\n",
      "0.06417825176156923\n",
      "\n",
      "0.9284603421461898\n",
      "0.04551513997333841\n",
      "\n",
      "0.21015401595344405\n",
      "0.2190059036374024\n",
      "\n",
      "0.13969401947148818\n",
      "0.13693957115009747\n",
      "\n",
      "0.4516272600834492\n",
      "0.44468810916179335\n",
      "\n",
      "0.024367176634214185\n",
      "0.020711500974658868\n",
      "\n",
      "0.015076495132127955\n",
      "0.011939571150097465\n",
      "\n",
      "0.2176356050069541\n",
      "0.2124756335282651\n",
      "\n",
      "[0.12721386402589982, 0.2190059036374024, 0.7539516282612836, 0.06417825176156923, 0.04551513997333841]\n",
      "[0.13693957115009747, 0.2124756335282651, 0.7268518518518519, 0.06115984405458089, 0.04191033138401559]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import brown\n",
    "from nltk import DefaultTagger as df\n",
    "from nltk import UnigramTagger as ut\n",
    "from nltk import BigramTagger as bt\n",
    "from nltk import TrigramTagger as tg\n",
    "\n",
    "\n",
    "patterns = [(r'.*ing$', 'VBG'), (r'.*ed$', 'VBD'), (r'.*es$', 'VBZ'), (r'.*ould$', 'MD'), (r'.*\\'s$', 'NN$'),               \n",
    "             (r'.*s$', 'NNS'), (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), (r'.*', 'NN')]\n",
    "\n",
    "\n",
    "\n",
    "def_model = nltk.DefaultTagger('NN')\n",
    "uni_model = nltk.UnigramTagger(tb_train_sents)\n",
    "bi_model = nltk.BigramTagger(tb_train_sents)\n",
    "tri_model = nltk.TrigramTagger(tb_train_sents)\n",
    "regexp_model = nltk.RegexpTagger(patterns)\n",
    "\n",
    "rb_models=[def_model,regexp_model,uni_model,bi_model,tri_model]\n",
    "\n",
    "# performance of Default Tagger\n",
    "print(def_model.evaluate(tb_train_sents))\n",
    "print(def_model.evaluate(tb_test_sents))\n",
    "print()\n",
    "# performance of Unigram Tagger\n",
    "print(uni_model.evaluate(tb_train_sents))\n",
    "print(uni_model.evaluate(tb_test_sents))\n",
    "print()\n",
    "# performance of Bigram Tagger\n",
    "print(bi_model.evaluate(tb_train_sents))\n",
    "print(bi_model.evaluate(tb_test_sents))\n",
    "print()\n",
    "# performance of Trigram Tagger\n",
    "print(tri_model.evaluate(tb_train_sents))\n",
    "print(tri_model.evaluate(tb_test_sents))\n",
    "print()\n",
    "# performance of Regex Tagger\n",
    "print(regexp_model.evaluate(tb_train_sents))\n",
    "print(regexp_model.evaluate(tb_test_sents))\n",
    "print()\n",
    "\n",
    "result_rb_treebank=[m.evaluate(tb_test_sents) for m in rb_models]\n",
    "\n",
    "\n",
    "# Train model based on Brown dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "brown_uni_model = nltk.UnigramTagger(bn_train_sents)\n",
    "brown_bi_model = nltk.BigramTagger(bn_train_sents)\n",
    "brown_tri_model = nltk.TrigramTagger(bn_train_sents)\n",
    "brown_regexp_model = nltk.RegexpTagger(patterns)\n",
    "\n",
    "brown_rb_models=[def_model,brown_regexp_model,brown_uni_model,brown_bi_model,brown_tri_model]\n",
    "# performance of Default Tagger\n",
    "print(def_model.evaluate(bn_train_sents))\n",
    "print(def_model.evaluate(bn_test_sents))\n",
    "print()\n",
    "# performance of Unigram Tagger\n",
    "print(uni_model.evaluate(bn_train_sents))\n",
    "print(uni_model.evaluate(bn_test_sents))\n",
    "print()\n",
    "# performance of Bigram Tagger\n",
    "print(bi_model.evaluate(bn_train_sents))\n",
    "print(bi_model.evaluate(bn_test_sents))\n",
    "print()\n",
    "# performance of Trigram Tagger\n",
    "print(tri_model.evaluate(bn_train_sents))\n",
    "print(tri_model.evaluate(bn_test_sents))\n",
    "print()\n",
    "# performance of Regex Tagger\n",
    "print(regexp_model.evaluate(bn_train_sents))\n",
    "print(regexp_model.evaluate(bn_test_sents))\n",
    "print()\n",
    "\n",
    "result_rb_brown=[m.evaluate(bn_test_sents) for m in brown_rb_models]\n",
    "\n",
    "print(result_rb_treebank)\n",
    "print(result_rb_brown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "bar",
         "x": [
          "Perfoemance 1.1",
          "Perfoemance 1.2",
          "Perfoemance 1.4",
          "Perfoemance 1.5"
         ],
         "y": [
          0.9099219196343553,
          0.8863073700247572,
          0.5414230019493177,
          0.5896686159844055
         ]
        }
       ],
       "layout": {
        "title": "Performance Results"
       }
      },
      "text/html": [
       "<div id=\"7d1a4b4c-c8ab-4aa4-83be-48e3610f0f44\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7d1a4b4c-c8ab-4aa4-83be-48e3610f0f44\", [{\"type\": \"bar\", \"x\": [\"Perfoemance 1.1\", \"Perfoemance 1.2\", \"Perfoemance 1.4\", \"Perfoemance 1.5\"], \"y\": [0.9099219196343553, 0.8863073700247572, 0.5414230019493177, 0.5896686159844055]}], {\"title\": \"Performance Results\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"7d1a4b4c-c8ab-4aa4-83be-48e3610f0f44\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7d1a4b4c-c8ab-4aa4-83be-48e3610f0f44\", [{\"type\": \"bar\", \"x\": [\"Perfoemance 1.1\", \"Perfoemance 1.2\", \"Perfoemance 1.4\", \"Perfoemance 1.5\"], \"y\": [0.9099219196343553, 0.8863073700247572, 0.5414230019493177, 0.5896686159844055]}], {\"title\": \"Performance Results\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly as py\n",
    "import plotly.graph_objs\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "py.offline.iplot({\n",
    "    \"data\": [plotly.graph_objs.Bar( x=['Perfoemance 1.1', 'Perfoemance 1.2', 'Perfoemance 1.4', 'Perfoemance 1.5'], y=[clf.score(featuresrtn_test_tb, taggedrtn_test_tb), accuracy_tb, clf.score(featuresrtn_test_bn, taggedrtn_test_bn), accuracy_bn])],\n",
    "    \"layout\": Layout(title=\"Performance Results\")\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "bar",
         "x": [
          "Perfoemance 1.3.1",
          "Perfoemance 1.3.2",
          "Perfoemance 1.3.3",
          "Perfoemance 1.3.4",
          "Perfoemance 1.3.5",
          "Perfoemance 1.6.1",
          "Perfoemance 1.6.2",
          "Perfoemance 1.6.3",
          "Perfoemance 1.6.4",
          "Perfoemance 1.6.5"
         ],
         "y": [
          0.12721386402589982,
          0.2190059036374024,
          0.7539516282612836,
          0.06417825176156923,
          0.04551513997333841,
          0.13693957115009747,
          0.2124756335282651,
          0.7268518518518519,
          0.06115984405458089,
          0.04191033138401559
         ]
        }
       ],
       "layout": {
        "title": "Performance Results (Rule Based)"
       }
      },
      "text/html": [
       "<div id=\"95459d25-670d-4ccf-8799-105bf9f3be4b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"95459d25-670d-4ccf-8799-105bf9f3be4b\", [{\"type\": \"bar\", \"x\": [\"Perfoemance 1.3.1\", \"Perfoemance 1.3.2\", \"Perfoemance 1.3.3\", \"Perfoemance 1.3.4\", \"Perfoemance 1.3.5\", \"Perfoemance 1.6.1\", \"Perfoemance 1.6.2\", \"Perfoemance 1.6.3\", \"Perfoemance 1.6.4\", \"Perfoemance 1.6.5\"], \"y\": [0.12721386402589982, 0.2190059036374024, 0.7539516282612836, 0.06417825176156923, 0.04551513997333841, 0.13693957115009747, 0.2124756335282651, 0.7268518518518519, 0.06115984405458089, 0.04191033138401559]}], {\"title\": \"Performance Results (Rule Based)\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"95459d25-670d-4ccf-8799-105bf9f3be4b\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"95459d25-670d-4ccf-8799-105bf9f3be4b\", [{\"type\": \"bar\", \"x\": [\"Perfoemance 1.3.1\", \"Perfoemance 1.3.2\", \"Perfoemance 1.3.3\", \"Perfoemance 1.3.4\", \"Perfoemance 1.3.5\", \"Perfoemance 1.6.1\", \"Perfoemance 1.6.2\", \"Perfoemance 1.6.3\", \"Perfoemance 1.6.4\", \"Perfoemance 1.6.5\"], \"y\": [0.12721386402589982, 0.2190059036374024, 0.7539516282612836, 0.06417825176156923, 0.04551513997333841, 0.13693957115009747, 0.2124756335282651, 0.7268518518518519, 0.06115984405458089, 0.04191033138401559]}], {\"title\": \"Performance Results (Rule Based)\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "py.offline.iplot({\n",
    "    \"data\": [plotly.graph_objs.Bar( x=['Perfoemance 1.3.1', 'Perfoemance 1.3.2', 'Perfoemance 1.3.3', 'Perfoemance 1.3.4','Perfoemance 1.3.5','Perfoemance 1.6.1','Perfoemance 1.6.2','Perfoemance 1.6.3','Perfoemance 1.6.4','Perfoemance 1.6.5'], \n",
    "                                   y=result_rb_treebank+result_rb_brown)],\n",
    "    \"layout\": Layout(title=\"Performance Results (Rule Based)\")\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chinese Post Tagger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt','r', encoding = 'utf8') as f:\n",
    "    tagged = []\n",
    "    for line in f:\n",
    "        tagged.append([nltk.tag.str2tuple(t) for t in line.split() if nltk.tag.str2tuple(t)[1] is not None])\n",
    "    \n",
    "cn_tagged_sents=tagged[:1000]\n",
    "train_size = int(0.8 * len(cn_tagged_sents))\n",
    "\n",
    "cn_train_sents = cn_tagged_sents[:train_size]\n",
    "cn_test_sents = cn_tagged_sents[train_size:]\n",
    "\n",
    "# To features\n",
    "untag_train_cn, feature_train_cn, tag_train_cn = transform_to_dataset(cn_train_sents)\n",
    "untag_test_cn, feature_test_cn, tag_test_cn = transform_to_dataset(cn_test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8817931909494607\n"
     ]
    }
   ],
   "source": [
    "clf_cn = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "clf_cn.fit(feature_train_cn, tag_train_cn)\n",
    "score=clf_id.score(feature_test_cn, tag_test_cn)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since RDRPOSTagger and TreeTageer don't support the pre-trained model for Chinese , here I use the Standford POS tagger https://nlp.stanford.edu/software/tagger.shtml#About .\n",
    "### Using gui-command \"java -mx200m -cp \"stanford-postagger.jar;\" edu.stanford.nlp.tagger.maxent.MaxentTaggerGUI models/chinese-nodistsim.tagger\" to tag the test data, collect output result to text file \"standford_tag.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "thefile = open('test.txt', 'w',encoding = 'utf8')\n",
    "for item in untag_test_cn:\n",
    "  thefile.write(\"%s\\t\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031962449709432274\n"
     ]
    }
   ],
   "source": [
    "with open('standford_tag.txt','r', encoding = 'utf8') as f:\n",
    "    standford_result = []\n",
    "    for line in f:\n",
    "        for t in line.split():\n",
    "            standford_result.append(t.split('#'))\n",
    "            \n",
    "#print(standford_result)\n",
    "acc_cn = np.mean([x[1] == y for x, y in zip(standford_result, tag_test_cn)])\n",
    "print(acc_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "bar",
         "x": [
          "Performance 2.1 ",
          "Perfoemance 2.2"
         ],
         "y": [
          0.8817931909494607,
          0.031962449709432274
         ]
        }
       ],
       "layout": {
        "title": "Performance Results"
       }
      },
      "text/html": [
       "<div id=\"15e0a2f9-b131-4660-b67c-21f9056260db\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"15e0a2f9-b131-4660-b67c-21f9056260db\", [{\"type\": \"bar\", \"x\": [\"Performance 2.1 \", \"Perfoemance 2.2\"], \"y\": [0.8817931909494607, 0.031962449709432274]}], {\"title\": \"Performance Results\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"15e0a2f9-b131-4660-b67c-21f9056260db\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"15e0a2f9-b131-4660-b67c-21f9056260db\", [{\"type\": \"bar\", \"x\": [\"Performance 2.1 \", \"Perfoemance 2.2\"], \"y\": [0.8817931909494607, 0.031962449709432274]}], {\"title\": \"Performance Results\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "py.offline.iplot({\n",
    "    \"data\": [plotly.graph_objs.Bar( x=['Performance 2.1 ', 'Perfoemance 2.2'], y=[score,acc_cn])],\n",
    "    \"layout\": Layout(title=\"Performance Results\")\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
