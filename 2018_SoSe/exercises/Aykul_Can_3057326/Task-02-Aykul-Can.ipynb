{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Dataset 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6335,)\n",
      "(6335, 3)\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv('./fake_or_real_news.csv')\n",
    "y_1 = df_1.label\n",
    "print(y_1.shape)\n",
    "df_1 = df_1.drop('label', axis=1)\n",
    "print(df_1.shape)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(df_1['text'], y_1, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Vectorizers, I will be using only TFIDFVectorizer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDFVectorizer is being applied...\n",
      "(4244,)\n",
      "(4244, 56922)\n"
     ]
    }
   ],
   "source": [
    "print(\"TFIDFVectorizer is being applied...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train_1)\n",
    "print(X_train_1.shape)\n",
    "print(tfidf_train.shape)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SGD = SGDClassifier()\n",
    "clf_SVC = LinearSVC() \n",
    "clf_BNB = BernoulliNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic Gradient Descent is training with TFIDFVectorizer...\n",
      "Stochastic Gradient Descent is labeling on Training & Test Data with TFIDFVectorizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Stochastic Gradient Descent is training with TFIDFVectorizer...\")\n",
    "clf_SGD.fit(tfidf_train, y_train_1)\n",
    "print(\"Stochastic Gradient Descent is labeling on Training & Test Data with TFIDFVectorizer...\")\n",
    "SGD_prediction_on_training = clf_SGD.predict(tfidf_train)\n",
    "SGD_prediction_on_test = clf_SGD.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Helper Method for Plotting Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction of Labels(Fake/Real)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SGD on training dataset1:   0.999\n",
      "precision for SGD on training dataset1:   1.000\n",
      "recall for SGD on training dataset1:   0.999\n",
      "f1 for SGD on training dataset1:   0.999\n"
     ]
    }
   ],
   "source": [
    "SGD_score_on_training = metrics.accuracy_score(y_train_1, SGD_prediction_on_training)\n",
    "SGD_precision_on_training = metrics.precision_score(y_train_1, SGD_prediction_on_training, pos_label=\"REAL\")\n",
    "SGD_recall_on_training = metrics.recall_score(y_train_1, SGD_prediction_on_training, pos_label=\"REAL\")\n",
    "SGD_f1_on_training = metrics.f1_score(y_train_1, SGD_prediction_on_training, pos_label=\"REAL\")\n",
    "print(\"accuracy for SGD on training dataset1:   %0.3f\" % SGD_score_on_training)\n",
    "print(\"precision for SGD on training dataset1:   %0.3f\" % SGD_precision_on_training)\n",
    "print(\"recall for SGD on training dataset1:   %0.3f\" % SGD_recall_on_training)\n",
    "print(\"f1 for SGD on training dataset1:   %0.3f\" % SGD_f1_on_training)\n",
    "#cm = metrics.confusion_matrix(y_train_1, SGD_prediction_on_training, labels=['FAKE', 'REAL'])\n",
    "#plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])\n",
    "#print(\"Confusion matrix for SGD on training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SGD on test dataset1:   0.935\n",
      "precision for SGD on test dataset1:   0.962\n",
      "recall for SGD on test dataset1:   0.911\n",
      "f1 for SGD on test dataset1:   0.936\n"
     ]
    }
   ],
   "source": [
    "SGD_score_on_test = metrics.accuracy_score(y_test_1, SGD_prediction_on_test)\n",
    "SGD_precision_on_test = metrics.precision_score(y_test_1, SGD_prediction_on_test, pos_label=\"REAL\")\n",
    "SGD_recall_on_test = metrics.recall_score(y_test_1, SGD_prediction_on_test, pos_label=\"REAL\")\n",
    "SGD_f1_on_test = metrics.f1_score(y_test_1, SGD_prediction_on_test, pos_label=\"REAL\")\n",
    "print(\"accuracy for SGD on test dataset1:   %0.3f\" % SGD_score_on_test)\n",
    "print(\"precision for SGD on test dataset1:   %0.3f\" % SGD_precision_on_test)\n",
    "print(\"recall for SGD on test dataset1:   %0.3f\" % SGD_recall_on_test)\n",
    "print(\"f1 for SGD on test dataset1:   %0.3f\" % SGD_f1_on_test)\n",
    "#cm = metrics.confusion_matrix(y_test_1, SGD_prediction_on_test, labels=['FAKE', 'REAL'])\n",
    "#plot_confusion_matrix(cm, classes=['FAKE', 'REAL'])\n",
    "#print(\"Confusion matrix for SGD on test data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DO CROSS VALIDATION ON CONFIGURATION 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1639: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies:  [0.93533123 0.94479495 0.91955836 0.93533123 0.94164038]\n",
      "precisions:  [0.96308725 0.95221843 0.94620253 0.96245734 0.96402878]\n",
      "recalls:  [0.89589905 0.92105263 0.91463415 0.90675241 0.90443686]\n",
      "f1:  [0.93610224 0.93243243 0.92113565 0.93046358 0.93706294]\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=5, train_size=0.75, random_state=4222)\n",
    "#create scorers\n",
    "accuracy_scorer = make_scorer(accuracy_score)\n",
    "precision_scorer = make_scorer(precision_score, pos_label='REAL')\n",
    "recall_scorer = make_scorer(recall_score, pos_label='REAL')\n",
    "f1_scorer = make_scorer(f1_score, pos_label=('REAL'))\n",
    "all_data_countVec = tfidf_vectorizer.fit_transform(df_1['text'])\n",
    "accuracy_K_fold = cross_val_score(clf_SGD, all_data_countVec, y_1, cv=cv, scoring=accuracy_scorer)\n",
    "precision_K_fold = cross_val_score(clf_SGD, all_data_countVec, y_1, cv=cv, scoring=precision_scorer)\n",
    "recall_K_fold = cross_val_score(clf_SGD, all_data_countVec, y_1, cv=cv, scoring=recall_scorer)\n",
    "f1_K_fold = cross_val_score(clf_SGD, all_data_countVec, y_1, cv=cv, scoring=f1_scorer)\n",
    "print(\"accuracies: \", accuracy_K_fold)\n",
    "print(\"precisions: \", precision_K_fold)\n",
    "print(\"recalls: \", recall_K_fold)\n",
    "print(\"f1: \", f1_K_fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Dataset 2 and manipulate its labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240,)\n",
      "(1284,)\n",
      "(1267,)\n",
      "(10240, 1)\n",
      "(1284, 1)\n",
      "(1267, 1)\n"
     ]
    }
   ],
   "source": [
    "df_2_train = pd.read_csv('./liar_dataset/train.tsv', sep='\\t', usecols=[1, 2], names=['label', 'text'])\n",
    "df_2_validation = pd.read_csv('./liar_dataset/valid.tsv', sep='\\t', usecols=[1, 2], names=['label', 'text'])\n",
    "df_2_test = pd.read_csv('./liar_dataset/test.tsv', sep='\\t', usecols=[1, 2], names=['label', 'text'])\n",
    "#To calculate precision & recall, I make the following mapping on dataset2:\n",
    "#false & pants on fire -> false\n",
    "#barely true & half true & mostly true -> true\n",
    "df_2_train.loc[df_2_train['label'] == 'true', 'label'] = 'REAL'\n",
    "df_2_train.loc[df_2_train['label'] == 'mostly-true', 'label'] = 'REAL'\n",
    "df_2_train.loc[df_2_train['label'] == 'barely-true', 'label'] = 'REAL'\n",
    "df_2_train.loc[df_2_train['label'] == 'half-true', 'label'] = 'REAL'\n",
    "df_2_train.loc[df_2_train['label'] == 'false', 'label'] = 'FAKE'\n",
    "df_2_train.loc[df_2_train['label'] == 'pants-fire', 'label'] = 'FAKE'\n",
    "\n",
    "df_2_validation.loc[df_2_validation['label'] == 'true', 'label'] = 'REAL'\n",
    "df_2_validation.loc[df_2_validation['label'] == 'mostly-true', 'label'] = 'REAL'\n",
    "df_2_validation.loc[df_2_validation['label'] == 'barely-true', 'label'] = 'REAL'\n",
    "df_2_validation.loc[df_2_validation['label'] == 'half-true', 'label'] = 'REAL'\n",
    "df_2_validation.loc[df_2_validation['label'] == 'false', 'label'] = 'FAKE'\n",
    "df_2_validation.loc[df_2_validation['label'] == 'pants-fire', 'label'] = 'FAKE'\n",
    "\n",
    "df_2_test.loc[df_2_test['label'] == 'true', 'label'] = 'REAL'\n",
    "df_2_test.loc[df_2_test['label'] == 'mostly-true', 'label'] = 'REAL'\n",
    "df_2_test.loc[df_2_test['label'] == 'barely-true', 'label'] = 'REAL'\n",
    "df_2_test.loc[df_2_test['label'] == 'half-true', 'label'] = 'REAL'\n",
    "df_2_test.loc[df_2_test['label'] == 'false', 'label'] = 'FAKE'\n",
    "df_2_test.loc[df_2_test['label'] == 'pants-fire', 'label'] = 'FAKE'\n",
    "\n",
    "y_2_train = df_2_train.label\n",
    "print(y_2_train.shape)\n",
    "y_2_validation = df_2_validation.label\n",
    "print(y_2_validation.shape)\n",
    "y_2_test = df_2_test.label\n",
    "print(y_2_test.shape)\n",
    "\n",
    "df_2_train = df_2_train.drop('label', axis=1)\n",
    "print(df_2_train.shape)\n",
    "df_2_validation = df_2_validation.drop('label', axis=1)\n",
    "print(df_2_validation.shape)\n",
    "df_2_test = df_2_test.drop('label', axis=1)\n",
    "print(df_2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create TFIDFVector and fit the model with training dataset's TFIDFVector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC is training with TFIDFVectorizer...\n",
      "SVC is labeling on Training & Test Data with TFIDFVectorizer...\n"
     ]
    }
   ],
   "source": [
    "tfidf_train = tfidf_vectorizer.fit_transform(df_2_train.text)\n",
    "tfidf_validation = tfidf_vectorizer.transform(df_2_validation.text)\n",
    "tfidf_test = tfidf_vectorizer.transform(df_2_test.text)\n",
    "print(\"SVC is training with TFIDFVectorizer...\")\n",
    "clf_SVC.fit(tfidf_train, y_2_train)\n",
    "print(\"SVC is labeling on Training & Test Data with TFIDFVectorizer...\")\n",
    "SVC_prediction_on_training = clf_SVC.predict(tfidf_train)\n",
    "SVC_prediction_on_validation = clf_SVC.predict(tfidf_validation)\n",
    "SVC_prediction_on_test = clf_SVC.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction of Labels(Fake/Real) on TRAIN - VALIDATION - TEST data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVC on training dataset2:   0.922\n",
      "precision for SVC on training dataset2:   0.911\n",
      "recall for SVC on training dataset2:   0.989\n",
      "f1 for SVC on training dataset2:   0.948\n"
     ]
    }
   ],
   "source": [
    "SVC_score_on_training = metrics.accuracy_score(y_2_train, SVC_prediction_on_training)\n",
    "SVC_precision_on_training = metrics.precision_score(y_2_train, SVC_prediction_on_training, pos_label=\"REAL\")\n",
    "SVC_recall_on_training = metrics.recall_score(y_2_train, SVC_prediction_on_training, pos_label=\"REAL\")\n",
    "SVC_f1_on_training = metrics.f1_score(y_2_train, SVC_prediction_on_training, pos_label=\"REAL\")\n",
    "print(\"accuracy for SVC on training dataset2:   %0.3f\" % SVC_score_on_training)\n",
    "print(\"precision for SVC on training dataset2:   %0.3f\" % SVC_precision_on_training)\n",
    "print(\"recall for SVC on training dataset2:   %0.3f\" % SVC_recall_on_training)\n",
    "print(\"f1 for SVC on training dataset2:   %0.3f\" % SVC_f1_on_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVC on validation dataset2:   0.677\n",
      "precision for SVC on validation dataset2:   0.735\n",
      "recall for SVC on validation dataset2:   0.848\n",
      "f1 for SVC on validation dataset2:   0.787\n"
     ]
    }
   ],
   "source": [
    "SVC_score_on_validation = metrics.accuracy_score(y_2_validation, SVC_prediction_on_validation)\n",
    "SVC_precision_on_validation = metrics.precision_score(y_2_validation, SVC_prediction_on_validation, pos_label=\"REAL\")\n",
    "SVC_recall_on_validation = metrics.recall_score(y_2_validation, SVC_prediction_on_validation, pos_label=\"REAL\")\n",
    "SVC_f1_on_validation = metrics.f1_score(y_2_validation, SVC_prediction_on_validation, pos_label=\"REAL\")\n",
    "print(\"accuracy for SVC on validation dataset2:   %0.3f\" % SVC_score_on_validation)\n",
    "print(\"precision for SVC on validation dataset2:   %0.3f\" % SVC_precision_on_validation)\n",
    "print(\"recall for SVC on validation dataset2:   %0.3f\" % SVC_recall_on_validation)\n",
    "print(\"f1 for SVC on validation dataset2:   %0.3f\" % SVC_f1_on_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVC on test dataset2:   0.695\n",
      "precision for SVC on test dataset2:   0.755\n",
      "recall for SVC on test dataset2:   0.861\n",
      "f1 for SVC on test dataset2:   0.805\n"
     ]
    }
   ],
   "source": [
    "SVC_score_on_test = metrics.accuracy_score(y_2_test, SVC_prediction_on_test)\n",
    "SVC_precision_on_test = metrics.precision_score(y_2_test, SVC_prediction_on_test, pos_label=\"REAL\")\n",
    "SVC_recall_on_test = metrics.recall_score(y_2_test, SVC_prediction_on_test, pos_label=\"REAL\")\n",
    "SVC_f1_on_test = metrics.f1_score(y_2_test, SVC_prediction_on_test, pos_label=\"REAL\")\n",
    "print(\"accuracy for SVC on test dataset2:   %0.3f\" % SVC_score_on_test)\n",
    "print(\"precision for SVC on test dataset2:   %0.3f\" % SVC_precision_on_test)\n",
    "print(\"recall for SVC on test dataset2:   %0.3f\" % SVC_recall_on_test)\n",
    "print(\"f1 for SVC on test dataset2:   %0.3f\" % SVC_f1_on_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for SVC on test dataset1:   0.921\n",
      "precision for SVC on test dataset1:   0.943\n",
      "recall for SVC on test dataset1:   0.902\n",
      "f1 for SVC on test dataset1:   0.922\n",
      "----\n",
      "accuracy for SGD on test dataset2:   0.726\n",
      "precision for SGD on test dataset2:   0.739\n",
      "recall for SGD on test dataset2:   0.965\n",
      "f1 for SGD on test dataset2:   0.837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/egebuyuksemerci/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_SVC.fit(tfidf_vectorizer.transform(X_train_1), y_train_1)\n",
    "predict_SVC_on_ds1 = clf_SVC.predict(tfidf_vectorizer.transform(X_test_1))\n",
    "\n",
    "SVC_score_on_test = metrics.accuracy_score(y_test_1, predict_SVC_on_ds1)\n",
    "SVC_precision_on_test = metrics.precision_score(y_test_1, predict_SVC_on_ds1, pos_label=\"REAL\")\n",
    "SVC_recall_on_test = metrics.recall_score(y_test_1, predict_SVC_on_ds1, pos_label=\"REAL\")\n",
    "SVC_f1_on_test = metrics.f1_score(y_test_1, predict_SVC_on_ds1, pos_label=\"REAL\")\n",
    "print(\"accuracy for SVC on test dataset1:   %0.3f\" % SVC_score_on_test)\n",
    "print(\"precision for SVC on test dataset1:   %0.3f\" % SVC_precision_on_test)\n",
    "print(\"recall for SVC on test dataset1:   %0.3f\" % SVC_recall_on_test)\n",
    "print(\"f1 for SVC on test dataset1:   %0.3f\" % SVC_f1_on_test)\n",
    "\n",
    "print(\"----\")\n",
    "clf_SGD.fit(tfidf_vectorizer.transform(df_2_train.text), y_2_train)\n",
    "predict_SGD_on_ds2 = clf_SGD.predict(tfidf_vectorizer.transform(df_2_test.text))\n",
    "\n",
    "SGD_score_on_test = metrics.accuracy_score(y_2_test, predict_SGD_on_ds2)\n",
    "SGD_precision_on_test = metrics.precision_score(y_2_test, predict_SGD_on_ds2, pos_label=\"REAL\")\n",
    "SGD_recall_on_test = metrics.recall_score(y_2_test, predict_SGD_on_ds2, pos_label=\"REAL\")\n",
    "SGD_f1_on_test = metrics.f1_score(y_2_test, predict_SGD_on_ds2, pos_label=\"REAL\")\n",
    "print(\"accuracy for SGD on test dataset2:   %0.3f\" % SGD_score_on_test)\n",
    "print(\"precision for SGD on test dataset2:   %0.3f\" % SGD_precision_on_test)\n",
    "print(\"recall for SGD on test dataset2:   %0.3f\" % SGD_recall_on_test)\n",
    "print(\"f1 for SGD on test dataset2:   %0.3f\" % SGD_f1_on_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Firstly, fetch and split dataset3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing datasets\n",
      "ds1= ./fake_or_real_news.csv\n",
      "ds2= ./liar_dataset/train.tsv\n",
      "-- fake news\n",
      "Index(['y', 'claim'], dtype='object')\n",
      "3171\n",
      "3164\n",
      "6335\n",
      "-- liar liar\n",
      "Index(['y', 'claim'], dtype='object')\n",
      "{'false', 'true', 'half-true', 'barely-true', 'pants-fire', 'mostly-true'} 10240\n",
      "1676\n",
      "1995\n",
      "{'false', 'true'} 3671\n",
      "false    5159\n",
      "true     4847\n",
      "Name: y, dtype: int64\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def get_dataset3_split(dataset1_in, dataset2_in):\n",
    "    try:\n",
    "        print('processing datasets')\n",
    "        print('ds1=', dataset1_in)\n",
    "        print('ds2=', dataset2_in)\n",
    "\n",
    "        print('-- fake news')\n",
    "        df1 = pd.read_csv(dataset1_in, sep=',', usecols=['title','text','label'])\n",
    "        df1['claim'] = df1[['title', 'text']].apply(lambda x: '. '.join(x), axis=1)\n",
    "        del df1['title']\n",
    "        del df1['text']\n",
    "        df1.rename(index=str, columns={'label': 'y'}, inplace=True)\n",
    "        print(df1.keys())\n",
    "        print(len(df1[df1['y']=='REAL']))\n",
    "        print(len(df1[df1['y']=='FAKE']))\n",
    "        df1['y'] = np.where(df1['y'] == 'FAKE', 'false', 'true')\n",
    "        print(len(df1))\n",
    "\n",
    "        print('-- liar liar')\n",
    "        df2 = pd.read_csv(dataset2_in, sep='\\t', header=None, usecols=[1,2], names=['y', 'claim'])\n",
    "        print(df2.keys())\n",
    "        print(set(df2.y), len(df2))\n",
    "        print(len(df2[df2['y'] == 'true']))\n",
    "        print(len(df2[df2['y'] == 'false']))\n",
    "        df2=df2[(df2['y'] == 'true') | (df2['y'] == 'false')]\n",
    "        print(set(df2.y), len(df2))\n",
    "\n",
    "        df3=pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "        print(df3['y'].value_counts())\n",
    "        print('done')\n",
    "        return train_test_split(df3['claim'], df3['y'], test_size=0.30, random_state=4222)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "ds1 = './fake_or_real_news.csv' \n",
    "ds2 = './liar_dataset/train.tsv'\n",
    "ds3_train, ds3_test, ds3_y_train, ds3_y_test = get_dataset3_split(ds1,ds2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes is training with TFIDFVectorizer...\n",
      "Stochastic Gradient Descent is labeling on Training & Test Data with TFIDFVectorizer...\n"
     ]
    }
   ],
   "source": [
    "tfidf_train_ds3 = tfidf_vectorizer.fit_transform(ds3_train)\n",
    "tfidf_test_ds3 = tfidf_vectorizer.transform(ds3_test)\n",
    "tfidf_y_train_ds3 = tfidf_vectorizer.transform(ds3_y_train)\n",
    "tfidf_y_test_ds3 = tfidf_vectorizer.transform(ds3_y_test)\n",
    "print(\"Bernoulli Naive Bayes is training with TFIDFVectorizer...\")\n",
    "clf_BNB.fit(tfidf_train_ds3.toarray(), ds3_y_train)\n",
    "print(\"Stochastic Gradient Descent is labeling on Training & Test Data with TFIDFVectorizer...\")\n",
    "BNB_prediction_on_training = clf_BNB.predict(tfidf_train_ds3.toarray())\n",
    "BNB_prediction_on_test = clf_BNB.predict(tfidf_test_ds3.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for BNB on training dataset3:   0.749\n",
      "precision for BNB on training dataset3:   0.867\n",
      "recall for BNB on training dataset3:   0.563\n",
      "f1 for BNB on training dataset3:   0.683\n"
     ]
    }
   ],
   "source": [
    "BNB_score_on_training = metrics.accuracy_score(ds3_y_train, BNB_prediction_on_training)\n",
    "BNB_precision_on_training = metrics.precision_score(ds3_y_train, BNB_prediction_on_training, pos_label=\"true\")\n",
    "BNB_recall_on_training = metrics.recall_score(ds3_y_train, BNB_prediction_on_training, pos_label=\"true\")\n",
    "BNB_f1_on_training = metrics.f1_score(ds3_y_train, BNB_prediction_on_training, pos_label=\"true\")\n",
    "print(\"accuracy for BNB on training dataset3:   %0.3f\" % BNB_score_on_training)\n",
    "print(\"precision for BNB on training dataset3:   %0.3f\" % BNB_precision_on_training)\n",
    "print(\"recall for BNB on training dataset3:   %0.3f\" % BNB_recall_on_training)\n",
    "print(\"f1 for BNB on training dataset3:   %0.3f\" % BNB_f1_on_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for BNB on test dataset3:   0.719\n",
      "precision for BNB on test dataset3:   0.809\n",
      "recall for BNB on test dataset3:   0.563\n",
      "f1 for BNB on test dataset3:   0.664\n"
     ]
    }
   ],
   "source": [
    "BNB_score_on_test = metrics.accuracy_score(ds3_y_test, BNB_prediction_on_test)\n",
    "BNB_precision_on_test = metrics.precision_score(ds3_y_test, BNB_prediction_on_test, pos_label=\"true\")\n",
    "BNB_recall_on_test = metrics.recall_score(ds3_y_test, BNB_prediction_on_test, pos_label=\"true\")\n",
    "BNB_f1_on_test = metrics.f1_score(ds3_y_test, BNB_prediction_on_test, pos_label=\"true\")\n",
    "print(\"accuracy for BNB on test dataset3:   %0.3f\" % BNB_score_on_test)\n",
    "print(\"precision for BNB on test dataset3:   %0.3f\" % BNB_precision_on_test)\n",
    "print(\"recall for BNB on test dataset3:   %0.3f\" % BNB_recall_on_test)\n",
    "print(\"f1 for BNB on test dataset3:   %0.3f\" % BNB_f1_on_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
