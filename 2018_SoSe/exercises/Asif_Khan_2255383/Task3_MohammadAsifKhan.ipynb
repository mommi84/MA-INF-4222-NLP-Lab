{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Convolution1D, MaxPooling1D, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_model(max_features, embed_dim, sequence_length, recurrent_dropout):\n",
    "    \n",
    "    nn = Sequential()\n",
    "    nn.add(Embedding(max_features, embed_dim, input_length = sequence_length))\n",
    "    nn.add(SpatialDropout1D(dropout_1d))\n",
    "    nn.add(LSTM(lstm_out, dropout=dropout, recurrent_dropout=recurrent_dropout))\n",
    "    nn.add(Dense(2, activation='softmax'))\n",
    "    nn.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    \n",
    "    return nn\n",
    "\n",
    "def conv_model(max_features, embed_dim, sequence_length, num_filters, kernel_size):\n",
    "    \n",
    "    nn = Sequential()\n",
    "    nn.add(Embedding(max_features, embed_dim, input_length = sequence_length))\n",
    "    nn.add(Convolution1D(filters=num_filters, kernel_size=kernel_size, padding=\"valid\", activation=\"relu\", strides=1))\n",
    "    nn.add(MaxPooling1D(pool_size=2))\n",
    "    nn.add(Flatten())\n",
    "    nn.add(Dense(2, activation='softmax'))\n",
    "    nn.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "    \n",
    "    return nn\n",
    "\n",
    "def evaluate_model(nn, X_test, Y_test, X_validate, Y_validate, batch_size):\n",
    "    score, accuracy = nn.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "    print(\"score: %.2f\" % (score))\n",
    "    print(\"acc: %.2f\" % (accuracy))    \n",
    "    pos_cnt, neg_cnt, pos_ok, neg_ok = 0, 0, 0, 0\n",
    "    for x in range(len(X_validate)):\n",
    "        result = nn.predict(X_validate[x].reshape(1,X_test.shape[1]),batch_size=1,verbose = 2)[0]\n",
    "        if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "            if np.argmax(Y_validate[x]) == 0: neg_ok += 1\n",
    "            else: pos_ok += 1\n",
    "        if np.argmax(Y_validate[x]) == 0: neg_cnt += 1\n",
    "        else: pos_cnt += 1\n",
    "\n",
    "    print(\"pos_acc\", pos_ok/pos_cnt*100, \"%\")\n",
    "    print(\"neg_acc\", neg_ok/neg_cnt*100, \"%\")\n",
    "    X2 = ['what are u going to say about that? the truth, wassock?!']\n",
    "    X2 = tok.texts_to_sequences(X2)\n",
    "    print('Sentence to ID')\n",
    "    X2 = pad_sequences(X2, maxlen=26, dtype='int32', value=0)\n",
    "    print(X2)\n",
    "    print('Model-Prediction')\n",
    "    print(nn.predict(X2, batch_size=1, verbose = 2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters \n",
    "max_features = 500\n",
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "dropout = 0.1\n",
    "dropout_1d = 0.4\n",
    "recurrent_dropout = 0.1\n",
    "random_state = 4222\n",
    "validation_size = 1000\n",
    "batch_size = 16\n",
    "epochs=2\n",
    "verbose= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read and preprocess data\n",
    "\n",
    "df = pd.read_csv('dataset_sentiment.csv')\n",
    "df = df[['text','sentiment']]\n",
    "\n",
    "df = df[df.sentiment != \"Neutral\"]\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('rt',' '))\n",
    "df['text'] = df['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "    \n",
    "tok = Tokenizer(num_words=max_features, split=' ')\n",
    "tok.fit_on_texts(df['text'].values)\n",
    "X = tok.texts_to_sequences(df['text'].values)\n",
    "X = pad_sequences(X)\n",
    "Y = pd.get_dummies(df['sentiment']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split Dataset\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.30, random_state = random_state)\n",
    "\n",
    "X_validate = X_test[-validation_size:]\n",
    "Y_validate = Y_test[-validation_size:]\n",
    "X_test = X_test[:-validation_size]\n",
    "Y_test = Y_test[:-validation_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "13s - loss: 0.4374 - acc: 0.8148\n",
      "Epoch 2/2\n",
      "13s - loss: 0.3659 - acc: 0.8461\n",
      "score: 0.36\n",
      "acc: 0.85\n",
      "pos_acc 40.0 %\n",
      "neg_acc 97.10691823899371 %\n",
      "Sentence to ID\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  48  37\n",
      "  311 189   4 144  22  16   1 281]]\n",
      "Model-Prediction\n",
      "[ 0.95043731  0.04956275]\n"
     ]
    }
   ],
   "source": [
    "sequence_length = X.shape[1]\n",
    "nn = lstm_model(max_features, embed_dim, sequence_length, recurrent_dropout)\n",
    "nn.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=verbose)\n",
    "evaluate_model(nn, X_test, Y_test, X_validate, Y_validate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1s - loss: 0.4342 - acc: 0.8140\n",
      "Epoch 2/2\n",
      "1s - loss: 0.3289 - acc: 0.8579\n",
      "score: 0.36\n",
      "acc: 0.85\n",
      "pos_acc 45.36585365853659 %\n",
      "neg_acc 95.34591194968553 %\n",
      "Sentence to ID\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  48  37\n",
      "  311 189   4 144  22  16   1 281]]\n",
      "Model-Prediction\n",
      "[ 0.92360032  0.07639971]\n"
     ]
    }
   ],
   "source": [
    "# Improvement in terms of computation as well as performance, achieved by using Convolution layer\n",
    "nn1 = conv_model(max_features, embed_dim, sequence_length, num_filters=12, kernel_size=3)\n",
    "nn1.fit(X_train, Y_train, epochs = epochs, batch_size=batch_size, verbose=verbose)\n",
    "evaluate_model(nn1, X_test, Y_test, X_validate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rdflib import Namespace, Graph, Literal\n",
    "from rdflib.namespace import FOAF, OWL, XSD, RDFS, DCTERMS, DOAP, DC, RDF\n",
    "\n",
    "\n",
    "prov = Namespace('http://www.w3.org/ns/prov#')\n",
    "dcat = Namespace('http://www.w3.org/ns/dcat#')\n",
    "mexalgo = Namespace('http://mex.aksw.org/mex-algo#')\n",
    "mexperf = Namespace('http://mex.aksw.org/mex-perf#')\n",
    "mexcore = Namespace('http://mex.aksw.org/mex-core#')\n",
    "this = Namespace('http://mex.aksw.org/examples/')\n",
    "\n",
    "g = Graph()\n",
    "# Create Binding\n",
    "g.bind('dct',DCTERMS)\n",
    "g.bind('owl',OWL)\n",
    "g.bind('foaf',FOAF)\n",
    "g.bind('xsd', XSD)\n",
    "g.bind('rdfs', RDFS)\n",
    "g.bind('doap', DOAP)\n",
    "g.bind('dc', DC)\n",
    "g.bind('prov', prov)\n",
    "g.bind('dcat', dcat)\n",
    "g.bind('mexalgo',mexalgo)\n",
    "g.bind('mexperf',mexperf)\n",
    "g.bind('mexcore',mexcore)\n",
    "g.bind('this',this)\n",
    "\n",
    "g.add((this.khan_task3,RDF.type,mexcore.Experiment))\n",
    "g.add((this.khan_task3,RDF.type,mexcore.ApplicationContext))\n",
    "g.add((this.khan_task3,RDFS.label, Literal('2255383')))\n",
    "g.add((this.khan_task3,DCTERMS.date, Literal('2018-05-15',datatype=XSD.date)))\n",
    "g.add((this.khan_task3,FOAF.givenName, Literal('Asif')))\n",
    "g.add((this.khan_task3,FOAF.mbox, Literal('mak4086@gmail.com')))\n",
    "\n",
    "#Model-1\n",
    "g.add((this.configuration1,RDF.type,mexcore.ExperimentConfiguration))\n",
    "g.add((this.configuration1,prov.used, this.model1))\n",
    "g.add((this.configuration1,prov.wasStartedBy, this.khan_task3))\n",
    "\n",
    "#Model-2\n",
    "g.add((this.configuration2,RDF.type,mexcore.ExperimentConfiguration))\n",
    "g.add((this.configuration2,prov.used, this.model2))\n",
    "g.add((this.configuration2,prov.wasStartedBy, this.khan_task3))\n",
    "\n",
    "g.add((this.test,RDF.type,mexcore.Test))\n",
    "g.add((this.test,RDFS.label,Literal('Test')))\n",
    "\n",
    "g.add((this.hyerparameter_model1,RDF.type,mexalgo.HyperParameterCollection))\n",
    "g.add((this.hyerparameter1,RDFS.label,Literal('HyperParameterCollection')))\n",
    "g.add((this.hyerparameter_model1,prov.hadMember,this.hyerparameter1))\n",
    "g.add((this.hyerparameter_model1,prov.hadMember,this.hyerparameter2))\n",
    "g.add((this.hyerparameter_model1,prov.hadMember,this.hyerparameter3))\n",
    "\n",
    "\n",
    "g.add((this.hyerparameter_model2,RDF.type,mexalgo.HyperParameterCollection))\n",
    "g.add((this.hyerparameter_model2,RDFS.label,Literal('HyperParameterCollection')))\n",
    "g.add((this.hyerparameter_model2,prov.hadMember,this.hyerparameter4))\n",
    "g.add((this.hyerparameter_model2,prov.hadMember,this.hyerparameter5))\n",
    "g.add((this.hyerparameter_model2,prov.hadMember,this.hyerparameter6))\n",
    "\n",
    "\n",
    "g.add((this.hyerparameter1,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter1,RDFS.label, Literal('embedding_dimension')))\n",
    "g.add((this.hyerparameter1,DCTERMS.identifier, Literal('embedding_dimension')))\n",
    "g.add((this.hyerparameter1,prov.value, Literal('128',datatype=XSD.integer)))\n",
    "\n",
    "g.add((this.hyerparameter2,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter2,RDFS.label, Literal('dropout')))\n",
    "g.add((this.hyerparameter2,DCTERMS.identifier, Literal('dropout')))\n",
    "g.add((this.hyerparameter2,prov.value, Literal('0.1',datatype=XSD.float)))\n",
    "\n",
    "g.add((this.hyerparameter3,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter3,RDFS.label, Literal('recurrent_dropout')))\n",
    "g.add((this.hyerparameter3,DCTERMS.identifier, Literal('recurrent_dropout')))\n",
    "g.add((this.hyerparameter3,prov.value, Literal('0.1',datatype=XSD.float)))\n",
    "\n",
    "\n",
    "g.add((this.hyerparameter4,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter4,RDFS.label, Literal('embedding_dimension')))\n",
    "g.add((this.hyerparameter4,DCTERMS.identifier, Literal('embedding_dimension')))\n",
    "g.add((this.hyerparameter4,prov.value, Literal('128', datatype=XSD.integer)))\n",
    "\n",
    "g.add((this.hyerparameter5,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter5,RDFS.label, Literal('convolution_filters')))\n",
    "g.add((this.hyerparameter5,DCTERMS.identifier, Literal('convolution_filters')))\n",
    "g.add((this.hyerparameter5,prov.value, Literal('12',datatype=XSD.integer)))\n",
    "\n",
    "g.add((this.hyerparameter6,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter6,RDFS.label, Literal('filter_size')))\n",
    "g.add((this.hyerparameter6,DCTERMS.identifier, Literal('filter_size')))\n",
    "g.add((this.hyerparameter6,prov.value, Literal('3',datatype=XSD.integer)))\n",
    "\n",
    "\n",
    "g.add((this.dataset,RDF.type,mexcore.Dataset))\n",
    "g.add((this.dataset,RDFS.label,Literal('Sentiment-Classification')))\n",
    "g.add((this.dataset,DCTERMS.landingPage,Literal('https://github.com/SmartDataAnalytics/MA-INF-4222-NLP-Lab/blob/master/2018_SoSe/exercises/dataset_sentiment.csv')))\n",
    "\n",
    "\n",
    "g.add((this.execution1,RDF.type,mexcore.ExecutionOverall))\n",
    "g.add((this.execution1,prov.generated,this.performance_measures1))\n",
    "g.add((this.execution1,prov.used,this.test))\n",
    "g.add((this.execution1,prov.used,this.hyerparameter_model1))\n",
    "g.add((this.execution1,prov.used,this.model1))\n",
    "\n",
    "g.add((this.execution2,RDF.type,mexcore.ExecutionOverall))\n",
    "g.add((this.execution2,prov.generated,this.performance_measures2))\n",
    "g.add((this.execution2,prov.used,this.test))\n",
    "g.add((this.execution2,prov.used,this.hyerparameter_model2))\n",
    "g.add((this.execution2,prov.used,this.model2))\n",
    "\n",
    "\n",
    "g.add((this.performance_measures1,RDF.type,mexcore.PerformanceMeasure))\n",
    "g.add((this.performance_measures1,mexperf.score,Literal('0.36',datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,mexperf.accuracy,Literal('0.85',datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,mexperf.pos_accuracy,Literal('0.40',datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,mexperf.neg_accuracy,Literal('0.97',datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,prov.wasGeneratedBy,this.execution1))\n",
    "\n",
    "g.add((this.performance_measures2,RDF.type,mexcore.PerformanceMeasure))\n",
    "g.add((this.performance_measures2,mexperf.score,Literal('0.36',datatype=XSD.float)))\n",
    "g.add((this.performance_measures2,mexperf.accuracy,Literal('0.85',datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,mexperf.pos_accuracy,Literal('0.45',datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,mexperf.neg_accuracy,Literal('0.95',datatype=XSD.float)))\n",
    "g.add((this.performance_measures2,prov.wasGeneratedBy,this.execution2))\n",
    "\n",
    "\n",
    "g.add((this.model1,RDF.type,mexalgo.Algorithm))\n",
    "g.add((this.model1,RDFS.label,Literal('LSTM')))\n",
    "g.add((this.model1,DCTERMS.identifier,Literal('LSTM')))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyerparameter1))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyerparameter2))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyerparameter3))\n",
    "\n",
    "g.add((this.model2,RDF.type,mexalgo.Algorithm))\n",
    "g.add((this.model2,RDFS.label,Literal('TemporalConvolution')))\n",
    "g.add((this.model2,DCTERMS.identifier,Literal('TemporalConvolution')))\n",
    "g.add((this.model2,mexalgo.hasHyperParameter,this.hyerparameter4))\n",
    "g.add((this.model2,mexalgo.hasHyperParameter,this.hyerparameter5))\n",
    "g.add((this.model2,mexalgo.hasHyperParameter,this.hyerparameter6))\n",
    "\n",
    "with open('task3_metadata.ttl','wb') as f:\n",
    "    f.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
