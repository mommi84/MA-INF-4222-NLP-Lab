{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "for NLP lab SoSe18 by Nico Lutz\n",
    "\n",
    "the task2 will focus on basic fact-checking. It will consist in training 3 different models to perform over 3 different datasets (technically 2 different datasets + 1 merged)\n",
    "\n",
    "#### Env:\n",
    "* python 3\n",
    "* sklearn\n",
    "* pandas\n",
    "\n",
    "#### Resources:\n",
    "* https://nlpforhackers.io/training-pos-tagger/\n",
    "* https://opendatascience.com/how-to-build-a-fake-news-classification-model/\n",
    "* [syncing the forked repo with the origin](https://github.com/desktop/desktop/issues/1785)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "import itertools\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "%pylab inline\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Dataset 1](https://github.com/GeorgeMcIntire/fake_real_news_dataset): Fake or Real news\n",
    "only FAKE and REAL labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./task2_datasets1_2/fake_or_real_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake count: 12656\n",
      "Real count: 12684\n"
     ]
    }
   ],
   "source": [
    "print('Fake count:',df[df['label']=='FAKE'].size)\n",
    "print('Real count:',df[df['label']=='REAL'].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make train/test split balanced on the labels, so the labels are roughly represented equaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Dataset 2](https://arxiv.org/pdf/1705.00648.pdf)\n",
    "labels of a different range: pants-fire,barely-\n",
    "true,  false, half-true, mostly-true, and true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path='./task2_datasets1_2/liar_liar_paints_on_fire/liar_dataset/'\n",
    "headers=['id','label','statement','subject','speaker','speakerstitle','stateinfo','party','barely-true','false','half-true','mostly-true','pants-on-fire','context']\n",
    "ds2_train_df = pd.read_csv(path+'train.tsv',sep='\\t', names=headers)\n",
    "ds2_test_df = pd.read_csv(path+'test.tsv',sep='\\t', names=headers)\n",
    "ds2_valid_df = pd.read_csv(path+'valid.tsv',sep='\\t',names=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speakerstitle</th>\n",
       "      <th>stateinfo</th>\n",
       "      <th>party</th>\n",
       "      <th>barely-true</th>\n",
       "      <th>false</th>\n",
       "      <th>half-true</th>\n",
       "      <th>mostly-true</th>\n",
       "      <th>pants-on-fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11972.json</td>\n",
       "      <td>true</td>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>immigration</td>\n",
       "      <td>rick-perry</td>\n",
       "      <td>Governor</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "      <td>Radio interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11685.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>jobs</td>\n",
       "      <td>katrina-shankland</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a news conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11096.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>military,veterans,voting-record</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>President-Elect</td>\n",
       "      <td>New York</td>\n",
       "      <td>republican</td>\n",
       "      <td>63</td>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>comments on ABC's This Week.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5209.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>medicare,message-machine-2012,campaign-adverti...</td>\n",
       "      <td>rob-cornilles</td>\n",
       "      <td>consultant</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>republican</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a radio show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9524.json</td>\n",
       "      <td>pants-fire</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>campaign-finance,legal-issues,campaign-adverti...</td>\n",
       "      <td>state-democratic-party-wisconsin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>democrat</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>a web video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       label                                          statement  \\\n",
       "0  11972.json        true  Building a wall on the U.S.-Mexico border will...   \n",
       "1  11685.json       false  Wisconsin is on pace to double the number of l...   \n",
       "2  11096.json       false  Says John McCain has done nothing to help the ...   \n",
       "3   5209.json   half-true  Suzanne Bonamici supports a plan that will cut...   \n",
       "4   9524.json  pants-fire  When asked by a reporter whether hes at the ce...   \n",
       "\n",
       "                                             subject  \\\n",
       "0                                        immigration   \n",
       "1                                               jobs   \n",
       "2                    military,veterans,voting-record   \n",
       "3  medicare,message-machine-2012,campaign-adverti...   \n",
       "4  campaign-finance,legal-issues,campaign-adverti...   \n",
       "\n",
       "                            speaker         speakerstitle  stateinfo  \\\n",
       "0                        rick-perry              Governor      Texas   \n",
       "1                 katrina-shankland  State representative  Wisconsin   \n",
       "2                      donald-trump       President-Elect   New York   \n",
       "3                     rob-cornilles            consultant     Oregon   \n",
       "4  state-democratic-party-wisconsin                   NaN  Wisconsin   \n",
       "\n",
       "        party  barely-true  false  half-true  mostly-true  pants-on-fire  \\\n",
       "0  republican           30     30         42           23             18   \n",
       "1    democrat            2      1          0            0              0   \n",
       "2  republican           63    114         51           37             61   \n",
       "3  republican            1      1          3            1              1   \n",
       "4    democrat            5      7          2            2              7   \n",
       "\n",
       "                        context  \n",
       "0               Radio interview  \n",
       "1             a news conference  \n",
       "2  comments on ABC's This Week.  \n",
       "3                  a radio show  \n",
       "4                   a web video  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "half-true      265\n",
       "false          249\n",
       "mostly-true    241\n",
       "barely-true    212\n",
       "true           208\n",
       "pants-fire      92\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds2_test_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#split\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "ds2_train = ds2_train_df['statement']\n",
    "ds2_y_train = ds2_train_df['label']\n",
    "ds2_y_train = lb.fit_transform(ds2_y_train)\n",
    "\n",
    "ds2_test = ds2_test_df['statement']\n",
    "ds2_y_test = ds2_test_df['label']\n",
    "ds2_y_test = lb.fit_transform(ds2_y_test)\n",
    "\n",
    "ds2_valid = ds2_valid_df['statement']\n",
    "ds2_y_valid = ds2_valid_df['label']\n",
    "ds2_y_valid = lb.fit_transform(ds2_y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3 - combination of 1 and 2\n",
    "copy and paste of script_dataset3.py provided by diegoesteves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing datasets\n",
      "ds1= ./task2_datasets1_2/fake_or_real_news.csv\n",
      "ds2= ./task2_datasets1_2/liar_liar_paints_on_fire/liar_dataset/train.tsv\n",
      "-- fake news\n",
      "Index(['y', 'claim'], dtype='object')\n",
      "3171\n",
      "3164\n",
      "6335\n",
      "-- liar liar\n",
      "Index(['y', 'claim'], dtype='object')\n",
      "{'mostly-true', 'pants-fire', 'true', 'half-true', 'barely-true', 'false'} 10240\n",
      "1676\n",
      "1995\n",
      "{'true', 'false'} 3671\n",
      "false    5159\n",
      "true     4847\n",
      "Name: y, dtype: int64\n",
      "done\n",
      "7004\n",
      "3002\n",
      "false The Battleship Debate. By Michael Shrimpton on October 30, 2016 Some Battleship Myths Busted \n",
      "The comments on last week’s column (Aberfan – Disaster Or Attack?) threw up some unexpected comments about battleships, and the causes of World War I. As you can tell, it was a wide-ranging discussion! It also showed that that a number of myths about battleships, not to mention the causes of World War I, are still prevalent. First however, some comments on the exciting presidential race. Trump or Clinton? \n",
      "I’m still predicting a win for Trump. The polls have tightened, which is not good news for Hillary, and the first straws in the wind suggesting a landslide for Trump have appeared. Some polls are still showing a lead for the Democrat, but the most reliable ones seem to be showing Trumpy ahead by 1 or 2 points. \n",
      "A delighted Washington Post predicted this week that Trumpy has “next to zero” chance of winning. I’m not sure that’s true even if you accept the polls as accurate. The polls are suggesting a tight race. However pollsters have a history of getting it wrong when it comes to races involving conservatives. The margin of error in favor of liberal positions differs from one pollster to another, but between 2.5 and 5% seems about right. \n",
      "Since the last two Republican candidates were scarcely conservatives, the reasonably good performance of most polling organisations in 2008 and 2012 has to be viewed with reserve. Polling performance breaks down when you have serious conservative opposition. They can be still an indicator, however, of momentum. The FBI (Photo credit: Hurricane Bianca) \n",
      "I have heard of October surprises , indeed the Democrats sprang one over Bimbogate, or at least gave it the good old college try. It might have been better choosing bimbos who had actually met the Republican candidate, or at least met him without witnesses present, but there it is. \n",
      "Having the FBI act with integrity when the suspect is the Democratic candidate for president and polling day is less than two weeks away wasn’t so much an October surprise as an October shock, no offense to the Fibbies intended. \n",
      "Assuming – just assuming – that this wasn’t part of a deal between Mr O and Mr T, whereby Mr T agreed to keep quiet about Mr O’s Kenyan/Zanzibari origins in exchange for Mr O backing off the FBI, the timing of the FBI’s move was extraordinary. They are saying that it was due to fresh evidence coming into their possession, so it can’t have been that. \n",
      "It is just possible that the boys in the Hoover building (that’s Hoover as in J Edgar, BTW, not as in the vacuum cleaner) were not aware of the large sums of money slushing, sorry finding, its way to the wife of their Deputy Director from the Clintons. It’s a bit of a mystery, and I don’t pretend to know the answer. Astonishing as it may sound, with respect, it may even be that the FBI have finally started to act with integrity and good faith. If so, that would be a positive development, although don’t expect the CIA to follow suit! If they did, the world really will have turned upside down. The CIA and Wikipedia WWI \n",
      "People sometimes ask me why I write for VeteransToday, given the lousy pay (!) The short answer is that they are good people and don’t interfere with my freedom of expression. VT is also something of an intelligence clearing house, however. I hope readers learn something from my weekly columns (that’s why I write ‘em), but I also learn things. \n",
      "One of the things I learnt this week via VT is that the CIA have a thing going with Wikipedia. I thought I was dealing with operatives – it was strange that so-called volunteer editors responded within minutes to any attempt by me to balance the Wikipedia attack piece on me. Turns out the CIA have an active interest in about 10% of Wiki sites, including mine. \n",
      "Given that Director Brennan is an enemy of mine, with Jesuit connections, I helped expose the role of the Jesuit Order in providing the pretext for World War I and the Agency are heavily penetrated by my bitter enemies the DVD, via the Correa/COREA Group in Frankfurt, that would make sense. \n",
      "The next installment in my WikiWar should be mediation. Goodness knows who they’ll suggest as a mediator – Angela Merkel probably, or the President of the European Commission. The mediator will definitely be driving a Volkswagen. The Naval Race Rear Admiral Sir Christoper Cradock \n",
      "I’m inter alia an intelligence historian , so it’s nice to turn to an historical topic. It is incredibly important to get history right – otherwise we just repeat the same mistakes. \n",
      "A number of commenters last week seemed to be laboring under the delusion, no offense intended, that World War I was started by the naval race between the British and German Empires. This nonsensical view, widely propagated since 1918 by German Intelligence and their allies, is still recycled on the BBC and by liberal faculty members, i.e. just about all of them. \n",
      "World War I was not started by the British Admiralty, nor by accident. It was started by the Germans, who set up the assassination of the Archduke Franz Ferdinand and his lovely wife Sophie on June 28th 1914. The German army was already mobilising, implementing a war plan drawn up years before. \n",
      "The build-up of the Imperial German Navy had similarly been underway for years, for purely offensive purposes. The German Navy was not designed to protect German interests abroad – its capital ships lacked the range and the habitability for that. It was aimed at bringing the Royal Navy’s Atlantic and Channel Fleets to battle in the North Sea (the famous Grand Fleet was only formed on the outbreak of war). \n",
      "There is no way the German Navy could have matched the rapid, hemispheric deployment of a battlecruiser squadron to the farthest reaches of the South Atlantic in 1914, e.g., after the destruction of a weak British squadron under Rear-Admiral Sir Christopher Cradock at the Battle of Coronel. Vice-Admiral Sturdee’s great victory in the Battle of the Falkland Islands was of course made possible by the Naval Intelligence Department. \n",
      "The boys had spotted that the First Sea Lord, von Battenberg, was a German spy and had deliberately refused to reinforce Cradock’s squadron. Von Battenberg was left in place and fed false position reports – no wonder the sight of the fighting tops of a British battlecruiser squadron in Port Stanley harbor so rattled the Hun commander, Graf von Spee, who was the runner-up in the battle which followed. The true position was stated millennia ago by the Roman general Vegetius: si vis pacem, para bellum. If you wan’t peace, prepare for war. Great Britain did not encourage the First World War by taking the limited steps that she did to prepare for it. \n",
      "We needed more battleships and battlecruisers, not fewer. Sadly, the Liberal government decided to encourage German aggression by holding back spending on the Royal Navy. Had we been stronger, the Hun would not dare have invaded Belgium and Luxembourg in a flanking attack on the French army. Next Myth HMS Barham \n",
      "The next myth propagated last week was that battleships were vulnerable to U-Boats. The truth is that the only British battleships sunk by U-Boat in both world wars, HMS Barham and HMS Royal Oak, were betrayed. \n",
      "Royal Oak was sunk because the First Sea Lord Sir Dudley Pound was being blackmailed by Jerry and agreed to hold up the badly-needed block-ships requested for Scapa Flow by the C-in-C Home Fleet. \n",
      "Had the block-ships been in place, as requested, Gunther Prien wouldn’t have got within five miles of Royal Oak. It is not even clear that the dear old Barham was actually sunk in November 1941 by U-331. It is more likely that her magazines were detonated by a radio-controlled IED set off by a German agent on the battleship ahead, which happened to have a cameraman ready to film the sinking. \n",
      "All battleships after the turbine-powered Dreadnought were too fast for submarines, which until the advent of the first true submarine, the German Type XXI, had limited underwater speed and endurance. Forget the headline figure for underwater speed – at top speed a U-Boat’s batteries would be drained quickly. This made achieving a firing solution difficult. Battleships were also usually too well screened by destroyers. \n",
      "They were such difficult targets that in practice only a U-Boat lying in wait could torpedo them. Then there was the difficulty in sinking them. Older battleships could indeed be sunk by a single submarine, even a single torpedo, ditto battleships whose design was held back by the absurd limitations in the Washington Treaty, designed to make the next world war winnable for the Bad Guys. \n",
      "It is, however, intellectually dishonest to compare the latest subs with older battleships, or battleships, like the King George V class, designed to artificial limits. In World War II modern battleships designed without reference to the Washington Treaty, such as the wonderful Iowa class, incorporated excellent anti-torpedo protection. A single Jap sub, e.g. would have had trouble hitting an Iowa class fast battleship with enough torpedoes to sink her. \n",
      "The King George V classic were a classic illustration of the dangers posed by the Washington Treaty. To save weight their outer prop-shafts weren’t armored, a weakness which proved fatal when HMS Prince of Wales was struck by a Japanese aerial torpedo in December 1941. In practice battleships were much less vulnerable to torpedo attack than any other type of warship. That is why all Japanese submarine attacks on American battleships in World War II failed, indeed the Japs only ever managed to sink American battleships in harbor in peacetime, and even then they only actually sank two. The other battleships damaged at Pearl Harbor were repaired, modernised and went on to avenge their sisters. Third Myth HMS Repulse \n",
      "The vulnerability of battleships to air attack in World War II has also been greatly overstated. They were of course invulnerable to air attack in World War I, as no aircraft could carry an armor-piercing bomb heavy enough to sink them. No German or Italian battleship was sunk at sea by airpower in the whole of the war. \n",
      "No American battleship was sunk at sea in either war, period. Only one British battleship, HMS Prince of Wales, was sunk by airpower in World War II, and she was betrayed. HMS Indomitable, the carrier designated as her escort, had been run aground, on Pound’s orders, whilst working up out of Kingston Harbour in Jamaica. \n",
      "Attacking as they did outside fighter range, without combat equipment such self-sealing tanks, the Jap bombers would have been very vulnerable to Indomitable’s cannon-equipped fighters. \n",
      "As I explain in Spyhunter, Force Z’s course had been betrayed to the Japanese in Saigon, via radio, by the German spy Rear-Admiral Palliser. Had Palliser not betrayed the British squadron it’s unlikely that the Japs would have found them. They had poor air reconnaissance, limited fuel reserves and could not just stooge around the South China Sea trying to find them. \n",
      "HMS Repulse was a battlecruiser, not a battleship. Unlike her sister Renown, she had not been modernised. In particular, she lacked Renown’s modern 4.5” Dual Purpose (DP) battery, much more effective in the AA role than Prince of Wales’s DP fit. Bismarck firing at HMS Hood \n",
      "HMS Hood , blown-up during the course of the Battle of the Denmark Strait, was also a battlecruiser and, like Repulse, she had not been modernised. The Chamberlain government and the Treasury denied the Admiralty the funds for her much-needed modernisation, precisely in order to make her easier for Jerry to sink. \n",
      "As I explain in Spyhunter, it is very doubtful that Hood was actually sunk by KMS Bismarck and much more likely that she was blown up by an IED in either a 4” magazine, leading to secondary detonation of a main magazine, or a main magazine. \n",
      "None of the broadsides fired by either Bismarck or her accompanying heavy cruiser Prinz Eugen is a good candidate for the alleged fatal shot. Prinz Eugen’s main battery was only 8”/60 caliber – her 270 lb shells were too small to have penetrated Hood’s heavy belt armor. \n",
      "For decades, we have been favored with nonsense from pro-Germans about Hood’s main deck armor being much weaker than Bismarck’s (the true figures are 3” over the magazines for Hood and 4.7” for Bismarck) and Bismarck sinking her with plunging fire at long range. Bismarck, however, was photographed firing at Hood from the Prinz Eugen. As you can see from the photo, Bismarck’s main battery is nowhere near maximum elevation. \n",
      "The Hun-loving editors of Wikipedia, BTW, still cannot bring themselves to acknowledge that the Bismarck was sunk by the Royal Navy. She was in fact finished off by torpedoes from the heavy cruiser HMS Dorsetshire, sinking shortly after the last torpedo hit, which Wikipedia would have us believe was a strange coincidence. HMS King George V \n",
      "As I have mentioned, the King George V class , of which Prince of Wales was a member, suffered from design limitations imposed by the Washington Treaty. They also suffered from several design flaws, which would not have been repeated in later classes and partly flowed from the lack of cash given to the Admiralty in the 1930s. \n",
      "They sacrificed AA firepower for spotter aircraft. Whilst the planes were well-protected in an armored hangar, it would have been better to rely on more powerful spotter/recon aircraft flown from escorting carriers. \n",
      "The 5.25” DP secondary armament was an excellent anti-destroyer weapon, probably the best ever deployed on a battleship, but had too poor a rate of fire (around 12-16 rounds per minute) to be an effective weapon against aircraft. The dedicated AA gun, the multiple 2-pounder ‘pom-pom’, was the best in the world when it came into service in the late 1920s, but had been overtaken by the 40-mil Bofors. The mounts were not tri-axially stabilized and the class lacked tachymetric AA fire-control. These specific weaknesses however afford no grounds for saying that battleships generally were unduly vulnerable to aircraft. So far to the contrary, they were better able to stand up to bombs and torpedoes than carriers, were more stable gun platforms, had better firing arcs (this was particularly true of the US Navy – the Iowa class had superb firing arcs for their secondary and AA armament, e.g., whereas the firing arcs on the Essex-class carriers were limited) and better fire-control. Unsurprisingly, US fast carrier task forces in the Pacific used battleships to protect carriers against aircraft. HMS Inflexible \n",
      "Of the five British capital ships sunk during World War II, two were unmodernised battlecruisers, two were probably sunk by IEDs and all five were betrayed in one way, shape or form. Without the assistance of the Abwehr, including interference by political assets in Number 10, the Cabinet Office and the Treasury with their design or modernisation, probably none of them would have been sunk at all. \n",
      "The US Navy had the right idea. What was needed was balanced all-arms task forces, combining battlewagons, carriers, cruisers and destroyers. Admiral Henderson of the Royal Navy had in fact come up with the idea of fast carrier task forces protected by capital ships in the Mediterranean in the 1930s, but the Royal Navy lacked enough fast battleships and carriers to really make it work until 1945, with the British Pacific Fleet \n",
      "Oh yes, we were in the Pacific alright , although the lack of defense expenditure and serious planning for war by pro-German weanies in Downing St before the war meant that it took three years for us to get there. Apart that is from our fine armored carrier HMS Victorious, which served briefly in the Pacific in 1943, flying USN squadrons, an episode which would make a fine war movie, if a movie-maker could be found with the guts to make it. \n",
      "President Reagan also had the right idea in reactivating the Iowa class in the 80s. Had the Royal Navy not been forced to scrap HMS Vanguard, our last battleship, by the German asset Harold Macmillan, it is doubtful that General Galtieri would even have started the war. HMS Vanguard Falklands War \n",
      "The very thought of that elegant and powerful fast battleship , virtually immune from the Exocet sea-skimming missiles (her belt armor was too strong for an Exocet to penetrate) emerging from the gloom of the South Atlantic to pulverise the Argentine Fleet or smash up Argentine forces ashore, would have given the Argies the willies. Vanguard’s deck armor, BTW, would have been too strong for any bomb the Argentine Air Force could carry. \n",
      "No ship in the Argentine Navy could have remained operational after a single accurate broadside from HMS Vanguard, and she had fully-synthetic fire-control, i.e. could land her main battery guns on target whilst maneuvering. She was a formidable surface combatant. This Week’s Movie Review: Jack Reacher: Never Go Back (2016, dir. Edward Zwick) \n",
      "This movie is huge fun . The first Jack Reacher movie, also starring Tom Cruise, was also huge fun, with the Bad Guys getting whacked all over the place. It’s always nice to see dirty cops getting their come-uppance! We could do with Jack Reacher in Thames Valley. No jury would convict. \n",
      "Unusually for a sequel, this movie is as good as the original. If anything, it’s even better. Tom Cruise is excellent as the lead, although it was a disappointment for me that Robert Duvall was not retained. He’s one of my all-time favorite actors. Robert Knepper, as General Harkness, provides strong support, however, as does Cobie Smulders, who I think we’ll be seeing again. \n",
      "The plot, based around bent military contractors, is more believable than most of the anti-military, anti-American rubbish emerging from liberal Hollywood, and the heroes come from the military. The movie moves at a cracking pace, and you are kept in suspense until the end about whether Jack is a father or not. I’m not going to spoil it for you by revealing the plot! It’s well worth going to see.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "ds1 = './task2_datasets1_2/fake_or_real_news.csv'\n",
    "ds2 = path+'train.tsv' #should I merge the test and val file ? yes I should !\n",
    "\n",
    "def get_dataset3_split(dataset1_in, dataset2_in):\n",
    "    try:\n",
    "        print('processing datasets')\n",
    "        print('ds1=', dataset1_in)\n",
    "        print('ds2=', dataset2_in)\n",
    "\n",
    "        print('-- fake news')\n",
    "        df1 = pd.read_csv(dataset1_in, sep=',', usecols=['title','text','label'])\n",
    "        df1['claim'] = df1[['title', 'text']].apply(lambda x: '. '.join(x), axis=1)\n",
    "        del df1['title']\n",
    "        del df1['text']\n",
    "        df1.rename(index=str, columns={'label': 'y'}, inplace=True)\n",
    "        print(df1.keys())\n",
    "        print(len(df1[df1['y']=='REAL']))\n",
    "        print(len(df1[df1['y']=='FAKE']))\n",
    "        df1['y'] = np.where(df1['y'] == 'FAKE', 'false', 'true')\n",
    "        print(len(df1))\n",
    "\n",
    "        print('-- liar liar')\n",
    "        df2 = pd.read_csv(dataset2_in, sep='\\t', header=None, usecols=[1,2], names=['y', 'claim'])\n",
    "        print(df2.keys())\n",
    "        print(set(df2.y), len(df2))\n",
    "        print(len(df2[df2['y'] == 'true']))\n",
    "        print(len(df2[df2['y'] == 'false']))\n",
    "        df2=df2[(df2['y'] == 'true') | (df2['y'] == 'false')]\n",
    "        print(set(df2.y), len(df2))\n",
    "\n",
    "        df3=pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "        print(df3['y'].value_counts())\n",
    "        print('done')\n",
    "        return train_test_split(df3['claim'], df3['y'], test_size=0.30, random_state=35)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "ds3_train, ds3_test, ds3_y_train, ds3_y_test = get_dataset3_split(ds1,ds2)\n",
    "print(len(ds3_train))\n",
    "print(len(ds3_test))\n",
    "print(ds3_y_train.get_values()[1], ds3_train.get_values()[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    See full source and example: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration 1)\n",
    "Clf1: Simple MultonomialNB after this [article](https://github.com/kjam/random_hackery/blob/master/Attempting%20to%20detect%20fake%20news.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "count_vector = TfidfVectorizer(stop_words='english')\n",
    "count_vector.fit_transform(df['text'])\n",
    "ds1_x = count_vector.transform(df['text'])\n",
    "\n",
    "ds1_y = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf1 = MultinomialNB(alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake      0.889     0.932     0.910       604\n",
      "       real      0.935     0.895     0.915       664\n",
      "\n",
      "avg / total      0.914     0.912     0.913      1268\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake      0.872     0.928     0.899       595\n",
      "       real      0.932     0.879     0.905       672\n",
      "\n",
      "avg / total      0.904     0.902     0.902      1267\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake      0.864     0.927     0.895       590\n",
      "       real      0.932     0.873     0.902       677\n",
      "\n",
      "avg / total      0.900     0.898     0.898      1267\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake      0.866     0.937     0.900       585\n",
      "       real      0.942     0.875     0.907       682\n",
      "\n",
      "avg / total      0.907     0.904     0.904      1267\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake      0.847     0.930     0.886       575\n",
      "       real      0.937     0.860     0.897       691\n",
      "\n",
      "avg / total      0.896     0.892     0.892      1266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, random_state=4222)\n",
    "kf.get_n_splits(ds1_x)\n",
    "\n",
    "conf_1 = []\n",
    "conf_1p = []\n",
    "for train_index, test_index in kf.split(ds1_x, ds1_y):\n",
    "    clf1.fit(ds1_x[train_index],ds1_y[train_index])\n",
    "    pred_clf1_ds1 = clf1.predict(ds1_x[test_index])\n",
    "    cm = classification_report(pred_clf1_ds1, ds1_y[test_index], labels=['FAKE','REAL'], target_names=['fake','real'], digits=3)\n",
    "    conf_1.append(cm)\n",
    "    conf_1p.append(precision_recall_fscore_support(pred_clf1_ds1, ds1_y[test_index], labels=['FAKE','REAL'], average = 'weighted'))\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.05, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(ds1_x, ds1_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration 2)\n",
    "clf 2:  second model with sklearn\n",
    "using a pipeline of countvector and tfidf, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelsds2=[[1, 0, 0, 0, 0, 0],[0, 1, 0, 0, 0, 0],[0, 0, 1, 0, 0, 0],[0, 0, 0, 1, 0, 0],[0, 0, 0, 0, 1, 0],[0, 0, 0, 0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "       ...lti_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          n_jobs=1))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "clf2.fit(ds2_train, ds2_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "[1, 0, 0, 0, 0, 0]      0.544     0.985     0.701       914\n",
      "[0, 1, 0, 0, 0, 0]      0.594     0.978     0.739      1213\n",
      "[0, 0, 1, 0, 0, 0]      0.584     0.966     0.728      1278\n",
      "[0, 0, 0, 1, 0, 0]      0.552     0.966     0.703      1122\n",
      "[0, 0, 0, 0, 1, 0]      0.625     0.998     0.768       525\n",
      "[0, 0, 0, 0, 0, 1]      0.558     0.980     0.711       954\n",
      "\n",
      "avg / total      0.574     0.976     0.722      6006\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "pred_clf2_ds2_train = clf2.predict(ds2_train)\n",
    "conf_2_train = classification_report(pred_clf2_ds2_train, ds2_y_train , target_names = labelsds2, digits=3)\n",
    "print(conf_2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "[1, 0, 0, 0, 0, 0]      0.071     0.250     0.110        60\n",
      "[0, 1, 0, 0, 0, 0]      0.137     0.382     0.201        89\n",
      "[0, 0, 1, 0, 0, 0]      0.072     0.235     0.110        81\n",
      "[0, 0, 0, 1, 0, 0]      0.050     0.174     0.077        69\n",
      "[0, 0, 0, 0, 1, 0]      0.033     0.200     0.056        15\n",
      "[0, 0, 0, 0, 0, 1]      0.062     0.236     0.099        55\n",
      "\n",
      "avg / total      0.080     0.260     0.122       369\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "pred_clf2_ds2_test = clf2.predict(ds2_test)\n",
    "conf_2_test = classification_report(pred_clf2_ds2_test, ds2_y_test , target_names = labelsds2, digits=3)\n",
    "conf2_p = precision_recall_fscore_support(pred_clf2_ds2_test, ds2_y_test, average = 'weighted')\n",
    "print(conf_2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "[1, 0, 0, 0, 0, 0]      0.076     0.265     0.118        68\n",
      "[0, 1, 0, 0, 0, 0]      0.122     0.320     0.176       100\n",
      "[0, 0, 1, 0, 0, 0]      0.109     0.252     0.152       107\n",
      "[0, 0, 0, 1, 0, 0]      0.088     0.275     0.133        80\n",
      "[0, 0, 0, 0, 1, 0]      0.086     0.455     0.145        22\n",
      "[0, 0, 0, 0, 0, 1]      0.065     0.212     0.100        52\n",
      "\n",
      "avg / total      0.096     0.280     0.142       429\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "pred_clf2_ds2_valid = clf2.predict(ds2_valid)\n",
    "conf_2_valid = classification_report(pred_clf2_ds2_valid, ds2_y_valid , target_names = labelsds2, digits=3)\n",
    "print(conf_2_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration 3\n",
    "model a on dataset ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "#binarified ds2\n",
    "ds2btest = ds2_test_df.copy()\n",
    "ds2btest.loc[ds2btest.label.str.contains(\"true\"),'label'] = 'REAL'\n",
    "ds2btest.loc[ds2btest.label.str.contains(\"false\"),'label'] = 'FAKE'\n",
    "ds2btest.loc[ds2btest.label.str.contains(\"pants-fire\"),'label'] = 'FAKE'\n",
    "\n",
    "ds2_x = count_vector.transform(ds2_test)\n",
    "ds2_y_test_binary = ds2btest.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_clf1_ds2 = clf1.predict(ds2_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       fake      0.290     0.312     0.301       317\n",
      "       real      0.765     0.745     0.755       950\n",
      "\n",
      "avg / total      0.646     0.637     0.641      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf3_1 = classification_report(pred_clf1_ds2, ds2_y_test_binary, labels=['FAKE','REAL'], target_names=['fake','real'], digits=3)\n",
    "print(conf3_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model b on ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2->5\n",
    "ds1_y_5 = []\n",
    "for each in ds1_y:\n",
    "    if each == 'FAKE': #FALSE\n",
    "        ds1_y_5.append([0, 1, 0, 0, 0, 0])\n",
    "    else:\n",
    "        ds1_y_5.append([0, 0, 0, 0, 0, 1])\n",
    "ds1_y_5=np.asarray(ds1_y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "pred_clf2_ds1 = clf2.predict(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "[1, 0, 0, 0, 0, 0]      0.000     0.000     0.000       164\n",
      "[0, 1, 0, 0, 0, 0]      0.017     0.711     0.033        76\n",
      "[0, 0, 1, 0, 0, 0]      0.000     0.000     0.000      1126\n",
      "[0, 0, 0, 1, 0, 0]      0.000     0.000     0.000       230\n",
      "[0, 0, 0, 0, 1, 0]      0.000     0.000     0.000        58\n",
      "[0, 0, 0, 0, 0, 1]      0.023     0.541     0.044       133\n",
      "\n",
      "avg / total      0.002     0.071     0.005      1787\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "conf3_2 = classification_report(pred_clf2_ds1, ds1_y_5 , target_names = labelsds2, digits=3)\n",
    "print(conf3_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0024157581633528847, 0.07050923335198657, 0.004661412144837637, None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py3k/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "conf3_21 = precision_recall_fscore_support(pred_clf2_ds1, ds1_y_5, average='weighted')\n",
    "print(conf3_21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration 4) \n",
    "Stacking Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train_ds3 = count_vectorizer.fit_transform(ds3_train)\n",
    "count_test_ds3 = count_vectorizer.transform(ds3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf3vc = RandomForestClassifier()\n",
    "X = count_train_ds3.toarray()\n",
    "clf3=clf3vc.fit(X, ds3_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = count_test_ds3.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_clf3_ds3= clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['false', 'true', 'false', ..., 'true', 'false', 'false'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_clf3_ds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7498054007805659, 0.729180546302465, 0.7330682192048681, None)\n"
     ]
    }
   ],
   "source": [
    "#ds3_train, ds3_test, ds3_y_train, ds3_y_test = get_dataset3_split(ds1,ds2)\n",
    "\n",
    "conf4 = precision_recall_fscore_support(pred_clf3_ds3, ds3_y_test, labels=['true', 'false'], average = 'weighted')\n",
    "print(conf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVcAAAEmCAYAAADWT9N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1129c01d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(ds3_y_test, pred_clf3_ds3, labels=['true', 'false'])\n",
    "plot_confusion_matrix(cm, classes=['FAKE', 'REAL'], title='Confusion Matrix of CLF3 on ds3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to rdf\n",
    "\n",
    "couldn't find a schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rdflib import Namespace, Graph, Literal\n",
    "from rdflib.namespace import FOAF, OWL, XSD, RDFS, DCTERMS, DOAP, DC\n",
    "\n",
    "\n",
    "prov = Namespace('http://www.w3.org/ns/prov#')\n",
    "dcat = Namespace('http://www.w3.org/ns/dcat#')\n",
    "mexalgo = Namespace('http://mex.aksw.org/mex-algo#')\n",
    "mexperf = Namespace('http://mex.aksw.org/mex-perf#')\n",
    "mexcore = Namespace('http://mex.aksw.org/mex-core#')\n",
    "this = Namespace('http://mex.aksw.org/examples/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "# Create Binding\n",
    "g.bind('dct',DCTERMS)\n",
    "g.bind('owl',OWL)\n",
    "g.bind('foaf',FOAF)\n",
    "g.bind('xsd', XSD)\n",
    "g.bind('rdfs', RDFS)\n",
    "g.bind('doap', DOAP)\n",
    "g.bind('dc', DC)\n",
    "g.bind('prov', prov)\n",
    "g.bind('dcat', dcat)\n",
    "g.bind('mexalgo',mexalgo)\n",
    "g.bind('mexperf',mexperf)\n",
    "g.bind('mexcore',mexcore)\n",
    "g.bind('this',this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g.add((this.nlp_ex2_nilutz,mexcore.Experiment, prov.Entity))\n",
    "g.add((this.nlp_ex2_nilutz,mexcore.ApplicationContext, prov.Entity))\n",
    "#g.add((this.nlp_ex2_nilutz,RDFS.label, Literal('2255383')))\n",
    "g.add((this.nlp_ex2_nilutz,DCTERMS.date, Literal('2018-05-20',datatype=XSD.date)))\n",
    "g.add((this.nlp_ex2_nilutz,FOAF.givenName, Literal('Nico')))\n",
    "\n",
    "#Configuration-1\n",
    "g.add((this.configuration1,mexcore.ExperimentConfiguration, prov.Entity))\n",
    "g.add((this.configuration1,prov.used, this.model1))\n",
    "g.add((this.configuration1,prov.wasStartedBy, this.nlp_ex2_nilutz))\n",
    "\n",
    "#Configuration-2\n",
    "g.add((this.configuration2,mexcore.ExperimentConfiguration, prov.Entity))\n",
    "g.add((this.configuration2,prov.used, this.model2))\n",
    "g.add((this.configuration2,prov.wasStartedBy, this.nlp_ex2_nilutz))\n",
    "\n",
    "#Configuration-3\n",
    "g.add((this.configuration3,mexcore.ExperimentConfiguration, prov.Entity))\n",
    "g.add((this.configuration3,prov.used, this.model2))\n",
    "g.add((this.configuration3,prov.used, this.model1))\n",
    "g.add((this.configuration3,prov.wasStartedBy, this.nlp_ex2_nilutz))\n",
    "\n",
    "#Configuration-4\n",
    "g.add((this.configuration4,mexcore.ExperimentConfiguration, prov.Entity))\n",
    "g.add((this.configuration4,prov.used, this.model4))\n",
    "g.add((this.configuration4,prov.wasStartedBy, this.nlp_ex2_nilutz))\n",
    "\n",
    "g.add((this.test,mexcore.Test,prov.Entity))\n",
    "g.add((this.test,RDFS.label,Literal('Test')))\n",
    "\n",
    "g.add((this.hyerparameter_model1,mexalgo.HyperParameterCollection,prov.Entity))\n",
    "g.add((this.hyerparameter1,RDFS.label,Literal('HyperParameterCollection')))\n",
    "g.add((this.hyerparameter_model1,prov.hadMember,this.hyerparameter1))\n",
    "\n",
    "g.add((this.hyerparameter1,mexalgo.HyperParameter,prov.Entity))\n",
    "g.add((this.hyerparameter1,RDFS.label, Literal('alpha')))\n",
    "g.add((this.hyerparameter1,DCTERMS.identifier, Literal('alpha')))\n",
    "g.add((this.hyerparameter1,prov.value, Literal('0.05',datatype=XSD.float)))\n",
    "\n",
    "g.add((this.dataset1,mexcore.Dataset,prov.Entity))\n",
    "g.add((this.dataset1,RDFS.label,Literal('Fake-News')))\n",
    "g.add((this.dataset1,DCTERMS.landingPage,Literal('https://github.com/GeorgeMcIntire/fake_real_news_dataset')))\n",
    "\n",
    "g.add((this.dataset2,mexcore.Dataset,prov.Entity))\n",
    "g.add((this.dataset2,RDFS.label,Literal('Liar-Liar')))\n",
    "g.add((this.dataset2,DCTERMS.landingPage,Literal('https://www.cs.ucsb.edu/william/data/liar_dataset.zip')))\n",
    "\n",
    "g.add((this.dataset3,mexcore.Dataset,prov.Entity))\n",
    "g.add((this.dataset3,RDFS.label,Literal('Fake-News+Liar-Liar')))\n",
    "g.add((this.dataset3,DCTERMS.landingPage,Literal('https://www.cs.ucsb.edu/william/data/liar_dataset.zip')))\n",
    "g.add((this.dataset3,DCTERMS.landingPage,Literal('https://github.com/GeorgeMcIntire/fake_real_news_dataset')))\n",
    "\n",
    "g.add((this.cross_validation,mexcore.crossValidation,prov.Entity))\n",
    "g.add((this.cross_validation,RDFS.label,Literal('cross validation')))\n",
    "g.add((this.cross_validation,mexcore.folds,Literal('5',datatype=XSD.integer)))\n",
    "g.add((this.cross_validation,mexcore.random_state,Literal('4222',datatype=XSD.integer)))\n",
    "\n",
    "g.add((this.execution1,mexcore.ExecutionOverall,prov.Entity))\n",
    "g.add((this.execution1,prov.generated,this.performance_measures1))\n",
    "g.add((this.execution1,prov.used,this.test))\n",
    "g.add((this.execution1,prov.used,this.hyerparameter_model1))\n",
    "g.add((this.execution1,prov.used,this.model1))\n",
    "\n",
    "g.add((this.execution2,mexcore.ExecutionOverall,prov.Entity))\n",
    "g.add((this.execution2,prov.generated,this.performance_measures2))\n",
    "g.add((this.execution2,prov.used,this.test))\n",
    "g.add((this.execution2,prov.used,this.model2))\n",
    "\n",
    "g.add((this.execution3,mexcore.ExecutionOverall,prov.Entity))\n",
    "g.add((this.execution3,prov.generated,this.performance_measures3))\n",
    "g.add((this.execution3,prov.used,this.test))\n",
    "g.add((this.execution3,prov.used,this.model2))\n",
    "g.add((this.execution3,prov.used,this.model3))\n",
    "\n",
    "g.add((this.execution4,mexcore.ExecutionOverall,prov.Entity))\n",
    "g.add((this.execution4,prov.generated,this.performance_measures4))\n",
    "g.add((this.execution4,prov.used,this.test))\n",
    "g.add((this.execution4,prov.used,this.model4))\n",
    "\n",
    "g.add((this.performance_measures1,mexcore.PerformanceMeasure,prov.Entity))\n",
    "g.add((this.performance_measures1,mexperf.precision,Literal(conf_1p[0][0],datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,mexperf.recall,Literal(conf_1p[0][1],datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,mexperf.accuracy,Literal(conf_1p[0][2],datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,prov.wasGeneratedBy,this.execution1))\n",
    "\n",
    "g.add((this.performance_measures2,mexcore.PerformanceMeasure,prov.Entity))\n",
    "g.add((this.performance_measures2,mexperf.precision,Literal(conf2_p[0],datatype=XSD.float)))\n",
    "g.add((this.performance_measures2,mexperf.recall,Literal(conf2_p[1],datatype=XSD.float)))\n",
    "g.add((this.performance_measures2,mexperf.accuracy,Literal(conf2_p[2],datatype=XSD.float)))\n",
    "g.add((this.performance_measures2,prov.wasGeneratedBy,this.execution2))\n",
    "\n",
    "g.add((this.performance_measures3,mexcore.PerformanceMeasure,prov.Entity))\n",
    "g.add((this.performance_measures3,mexperf.precision,Literal(conf3_21[0],datatype=XSD.float)))\n",
    "g.add((this.performance_measures3,mexperf.recall,Literal(conf3_21[1],datatype=XSD.float)))\n",
    "g.add((this.performance_measures3,mexperf.accuracy,Literal(conf3_21[2],datatype=XSD.float)))\n",
    "g.add((this.performance_measures3,prov.wasGeneratedBy,this.execution3))\n",
    "\n",
    "g.add((this.performance_measures4,mexcore.PerformanceMeasure,prov.Entity))\n",
    "g.add((this.performance_measures4,mexperf.precision,Literal(conf4[0],datatype=XSD.float)))\n",
    "g.add((this.performance_measures4,mexperf.recall,Literal(conf4[1],datatype=XSD.float)))\n",
    "g.add((this.performance_measures4,mexperf.accuracy,Literal(conf4[2],datatype=XSD.float)))\n",
    "g.add((this.performance_measures4,prov.wasGeneratedBy,this.execution4))\n",
    "\n",
    "\n",
    "g.add((this.model1,mexalgo.Algorithm,prov.Entity))\n",
    "g.add((this.model1,RDFS.label,Literal('MultinomialNB')))\n",
    "g.add((this.model1,DCTERMS.identifier,Literal('MultinomialNB')))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyerparameter1))\n",
    "\n",
    "g.add((this.model2,mexalgo.Algorithm,prov.Entity))\n",
    "g.add((this.model2,RDFS.label,Literal('OneVsRestClassifier')))\n",
    "g.add((this.model2,DCTERMS.identifier,Literal('OneVsRestClassifier')))\n",
    "\n",
    "g.add((this.model4,mexalgo.Algorithm,prov.Entity))\n",
    "g.add((this.model4,RDFS.label,Literal('RandomForestClassifier')))\n",
    "g.add((this.model4,DCTERMS.identifier,Literal('RandomForestClassifier')))\n",
    "\n",
    "with open('nico_lutz_meta_ex2.ttl','wb') as f:\n",
    "    f.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
