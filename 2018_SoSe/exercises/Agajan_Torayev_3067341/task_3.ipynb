{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, MaxPooling1D\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Activation, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from IPython import display\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate_confidence</th>\n",
       "      <th>relevant_yn</th>\n",
       "      <th>relevant_yn_confidence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_confidence</th>\n",
       "      <th>subject_matter</th>\n",
       "      <th>subject_matter_confidence</th>\n",
       "      <th>candidate_gold</th>\n",
       "      <th>...</th>\n",
       "      <th>relevant_yn_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>subject_matter_gold</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6578</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697200650592256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Scott Walker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.6333</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdeb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199560069120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.6629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:46 -0700</td>\n",
       "      <td>629697199312482304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No candidate mentioned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>0.7039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @RobGeorge: That Carly Fiorina is trending ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697197118861312</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>None of the above</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @DanScavino: #GOPDebate w/ @realDonaldTrump...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-07 09:54:45 -0700</td>\n",
       "      <td>629697196967903232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               candidate  candidate_confidence relevant_yn  \\\n",
       "0   1  No candidate mentioned                   1.0         yes   \n",
       "1   2            Scott Walker                   1.0         yes   \n",
       "2   3  No candidate mentioned                   1.0         yes   \n",
       "3   4  No candidate mentioned                   1.0         yes   \n",
       "4   5            Donald Trump                   1.0         yes   \n",
       "\n",
       "   relevant_yn_confidence sentiment  sentiment_confidence     subject_matter  \\\n",
       "0                     1.0   Neutral                0.6578  None of the above   \n",
       "1                     1.0  Positive                0.6333  None of the above   \n",
       "2                     1.0   Neutral                0.6629  None of the above   \n",
       "3                     1.0  Positive                1.0000  None of the above   \n",
       "4                     1.0  Positive                0.7045  None of the above   \n",
       "\n",
       "   subject_matter_confidence candidate_gold             ...              \\\n",
       "0                     1.0000            NaN             ...               \n",
       "1                     1.0000            NaN             ...               \n",
       "2                     0.6629            NaN             ...               \n",
       "3                     0.7039            NaN             ...               \n",
       "4                     1.0000            NaN             ...               \n",
       "\n",
       "  relevant_yn_gold retweet_count  sentiment_gold subject_matter_gold  \\\n",
       "0              NaN             5             NaN                 NaN   \n",
       "1              NaN            26             NaN                 NaN   \n",
       "2              NaN            27             NaN                 NaN   \n",
       "3              NaN           138             NaN                 NaN   \n",
       "4              NaN           156             NaN                 NaN   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  RT @NancyLeeGrahn: How did everyone feel about...         NaN   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdeb...         NaN   \n",
       "2  RT @TJMShow: No mention of Tamir Rice and the ...         NaN   \n",
       "3  RT @RobGeorge: That Carly Fiorina is trending ...         NaN   \n",
       "4  RT @DanScavino: #GOPDebate w/ @realDonaldTrump...         NaN   \n",
       "\n",
       "               tweet_created            tweet_id  tweet_location  \\\n",
       "0  2015-08-07 09:54:46 -0700  629697200650592256             NaN   \n",
       "1  2015-08-07 09:54:46 -0700  629697199560069120             NaN   \n",
       "2  2015-08-07 09:54:46 -0700  629697199312482304             NaN   \n",
       "3  2015-08-07 09:54:45 -0700  629697197118861312           Texas   \n",
       "4  2015-08-07 09:54:45 -0700  629697196967903232             NaN   \n",
       "\n",
       "                user_timezone  \n",
       "0                       Quito  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3  Central Time (US & Canada)  \n",
       "4                     Arizona  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/dataset_sentiment.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 13871\n",
       "unique                                                10402\n",
       "top       RT @RWSurferGirl: Jeb Bush reminds me of eleva...\n",
       "freq                                                    161\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count        13871\n",
       "unique           3\n",
       "top       Negative\n",
       "freq          8493\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df[['text', 'sentiment']]\n",
    "\n",
    "display.display(df['text'].describe())\n",
    "display.display(df['sentiment'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    8493\n",
       "Neutral     3142\n",
       "Positive    2236\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "# take only negative and positive sentiments\n",
    "df = df[df.sentiment != 'Neutral']\n",
    "\n",
    "# make lowercase text\n",
    "df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "\n",
    "# remove RT from text\n",
    "df['text'] = df['text'].apply(lambda x: x.replace('rt', ' '))\n",
    "\n",
    "# remove everything except letters, numbers and space\n",
    "df['text'] = df['text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scottwalker didnt catch the full gopdebate l...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robgeorge that carly fiorina is trending  ho...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>danscavino gopdebate w realdonaldtrump deliv...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gregabbott_tx tedcruz on my first day i will...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>warriorwoman91 i liked her and was happy whe...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "1    scottwalker didnt catch the full gopdebate l...  Positive\n",
       "3    robgeorge that carly fiorina is trending  ho...  Positive\n",
       "4    danscavino gopdebate w realdonaldtrump deliv...  Positive\n",
       "5    gregabbott_tx tedcruz on my first day i will...  Positive\n",
       "6    warriorwoman91 i liked her and was happy whe...  Negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['  scottwalker didnt catch the full gopdebate last night here are some of scotts best lines in 90 seconds walker16 httptcozsff',\n",
       "       '  robgeorge that carly fiorina is trending  hours after her debate  above any of the men in justcompleted gopdebate says shes on ',\n",
       "       '  danscavino gopdebate w realdonaldtrump delivered the highest ratings in the history of presidential debates trump2016 httptco',\n",
       "       ...,\n",
       "       '  lrihendry tedcruz as president i will always tell the truth and do what i said i would do  gopdebates',\n",
       "       '  jrehling gopdebate donald trump says that he doesnt have time for political correctness how does calling women fat pigs save him ',\n",
       "       '  lrihendry tedcruz headed into the presidential debates go ted \\n\\ngopdebates httptco8s67pz8a4a'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, \n",
    "                             X,\n",
    "                             Y,\n",
    "                             epochs, \n",
    "                             batch_size,\n",
    "                             tok):\n",
    "    \"\"\"Trains model and prints results.\n",
    "    \n",
    "    Args:\n",
    "        model: Keras `Sequential` model,\n",
    "        X:\n",
    "        Y:\n",
    "        epochs: `int` number of epochs\n",
    "        batch_size: `int` batch size,\n",
    "        max_features: `int` maximum features\n",
    "    \"\"\"\n",
    "    \n",
    "    validation_size = 1000\n",
    "    # split data set\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=4222)\n",
    "    X_validate = X_test[-validation_size:]\n",
    "    Y_validate = Y_test[-validation_size:]\n",
    "    X_test = X_test[:-validation_size]\n",
    "    Y_test = Y_test[:-validation_size]\n",
    "    \n",
    "    model.fit(X_train, Y_train, epochs=epochs, \n",
    "              batch_size=batch_size, verbose=2)\n",
    "    \n",
    "    score, accuracy = model.evaluate(X_test, Y_test, \n",
    "                                 batch_size=batch_size,\n",
    "                                 verbose=2)\n",
    "    print(\"Score: %.2f\" % score)\n",
    "    print(\"Accuracy: %.2f\" % accuracy)  \n",
    "    \n",
    "    pos_cnt, neg_cnt, pos_ok, neg_ok = 0, 0, 0, 0\n",
    "    for x in range(len(X_validate)):\n",
    "        result = model.predict(\n",
    "            X_validate[x].reshape(1, X_test.shape[1]),\n",
    "            batch_size=1,\n",
    "            verbose=2\n",
    "        )[0]\n",
    "\n",
    "        if np.argmax(result) == np.argmax(Y_validate[x]):\n",
    "            if np.argmax(Y_validate[x]) == 0: \n",
    "                neg_ok += 1\n",
    "            else:\n",
    "                pos_ok += 1\n",
    "\n",
    "        if np.argmax(Y_validate[x]) == 0:\n",
    "            neg_cnt += 1\n",
    "        else:\n",
    "            pos_cnt += 1\n",
    "\n",
    "    print(\"pos_acc\", pos_ok/pos_cnt*100, '%')\n",
    "    print(\"neg_acc\", neg_ok/neg_cnt*100, '%')\n",
    "    \n",
    "#     X2 = ['what are u going to say about that? the truth, wassock?!']\n",
    "#     X2 = tok.texts_to_sequences(X2)\n",
    "#     X2 = pad_sequences(X2, maxlen=maxlen, dtype='int32', value=0)\n",
    "#     print(X2)\n",
    "#     print(model.predict(X2, batch_size=1, verbose=2)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_model(df):\n",
    "    \"\"\"Trains model.\n",
    "    Args:\n",
    "        df: A Pandas `DataFrame`.\n",
    "    \"\"\"\n",
    "    \n",
    "    maxlen = 100\n",
    "    embed_dim = 128\n",
    "    lstm_out = 196\n",
    "    dropout = 0.1\n",
    "    dropout_1d = 0.4\n",
    "    recurrent_dropout = 0.1\n",
    "    batch_size = 16\n",
    "    epochs = 2\n",
    "    verbose = 2\n",
    "    max_features = 500\n",
    "    \n",
    "    tok = Tokenizer(num_words=max_features, split=' ')\n",
    "    tok.fit_on_texts(df['text'].values)\n",
    "    X = tok.texts_to_sequences(df['text'].values)\n",
    "    X = pad_sequences(X)\n",
    "    \n",
    "    # convert categorical variable into indicator variables\n",
    "    Y = pd.get_dummies(df['sentiment']).values\n",
    "    \n",
    "    # Build a model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add embedding\n",
    "    model.add(Embedding(max_features, embed_dim, \n",
    "                    input_length=X.shape[1]))\n",
    "\n",
    "    # Add Spatial Dropout\n",
    "    model.add(SpatialDropout1D(dropout_1d))\n",
    "\n",
    "    # Add LSTM\n",
    "    model.add(LSTM(lstm_out, \n",
    "               dropout=dropout, \n",
    "               recurrent_dropout=recurrent_dropout))\n",
    "\n",
    "    # Add output\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    train_and_evaluate_model(model, \n",
    "                             X,\n",
    "                             Y,\n",
    "                             epochs,\n",
    "                             batch_size,\n",
    "                             tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 26, 128)           64000     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 26, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 394       \n",
      "=================================================================\n",
      "Total params: 319,194\n",
      "Trainable params: 319,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      " - 44s - loss: 0.4363 - acc: 0.8168\n",
      "Epoch 2/2\n",
      " - 45s - loss: 0.3684 - acc: 0.8437\n",
      "Score: 0.36\n",
      "Accuracy: 0.86\n",
      "pos_acc 35.12195121951219 %\n",
      "neg_acc 97.86163522012579 %\n"
     ]
    }
   ],
   "source": [
    "default_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rcnn(df):\n",
    "    \"\"\"Trains model.\n",
    "    Args:\n",
    "        df: A Pandas `DataFrame`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Embedding\n",
    "    max_features = 5000\n",
    "    maxlen = 100\n",
    "    embedding_size = 256\n",
    "    \n",
    "    # Convolution\n",
    "    kernel_size = 5\n",
    "    filters = 64\n",
    "    pool_size = 4\n",
    "    \n",
    "    # LSTM\n",
    "    lstm_output_size = 70\n",
    "    \n",
    "    # Training\n",
    "    batch_size = 32\n",
    "    epochs = 2\n",
    "    \n",
    "    tok = Tokenizer(num_words=max_features, split=' ')\n",
    "    tok.fit_on_texts(df['text'].values)\n",
    "    X = tok.texts_to_sequences(df['text'].values)\n",
    "    X = pad_sequences(X)\n",
    "    \n",
    "    # convert categorical variable into indicator variables\n",
    "    Y = pd.get_dummies(df['sentiment']).values\n",
    "    \n",
    "    # Build a model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add embedding\n",
    "    model.add(Embedding(max_features, embedding_size, \n",
    "                    input_length=X.shape[1]))\n",
    "\n",
    "    # Add Dropout\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Add Convolution\n",
    "    model.add(Conv1D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        padding='valid',\n",
    "        activation='relu',\n",
    "        strides=1\n",
    "    ))\n",
    "    \n",
    "    # Add max pooling\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "\n",
    "    # Add LSTM\n",
    "    model.add(LSTM(lstm_output_size))\n",
    "\n",
    "    # Add output\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    # compile model\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    train_and_evaluate_model(model, \n",
    "                             X,\n",
    "                             Y,\n",
    "                             epochs,\n",
    "                             batch_size,\n",
    "                             tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 29, 256)           1280000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 29, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 25, 64)            81984     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 70)                37800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 142       \n",
      "=================================================================\n",
      "Total params: 1,399,926\n",
      "Trainable params: 1,399,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2\n",
      " - 15s - loss: 0.4198 - acc: 0.8244\n",
      "Epoch 2/2\n",
      " - 14s - loss: 0.2632 - acc: 0.8896\n",
      "Score: 0.35\n",
      "Accuracy: 0.86\n",
      "pos_acc 51.21951219512195 %\n",
      "neg_acc 94.9685534591195 %\n"
     ]
    }
   ],
   "source": [
    "rcnn(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exporting mex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Namespace, Graph, Literal\n",
    "from rdflib.namespace import FOAF, OWL, XSD, RDFS, DCTERMS, DOAP, DC, RDF\n",
    "\n",
    "prov = Namespace('http://www.w3.org/ns/prov#')\n",
    "dcat = Namespace('http://www.w3.org/ns/dcat#')\n",
    "mexalgo = Namespace('http://mex.aksw.org/mex-algo#')\n",
    "mexperf = Namespace('http://mex.aksw.org/mex-perf#')\n",
    "mexcore = Namespace('http://mex.aksw.org/mex-core#')\n",
    "this = Namespace('http://mex.aksw.org/examples/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph()\n",
    "g.bind('dct',DCTERMS)\n",
    "g.bind('owl',OWL)\n",
    "g.bind('foaf',FOAF)\n",
    "g.bind('xsd', XSD)\n",
    "g.bind('rdfs', RDFS)\n",
    "g.bind('doap', DOAP)\n",
    "g.bind('dc', DC)\n",
    "g.bind('prov', prov)\n",
    "g.bind('dcat', dcat)\n",
    "g.bind('mexalgo',mexalgo)\n",
    "g.bind('mexperf',mexperf)\n",
    "g.bind('mexcore',mexcore)\n",
    "g.bind('this',this)\n",
    "\n",
    "g.add((this.torayeff_exp_rcnn,RDF.type,mexcore.Experiment))\n",
    "g.add((this.torayeff_exp_rcnn,RDF.type,mexcore.ApplicationContext))\n",
    "g.add((this.torayeff_exp_rcnn,RDFS.label, Literal('3067341')))\n",
    "g.add((this.torayeff_exp_rcnn,DCTERMS.date, Literal('2018-05-28',datatype=XSD.date)))\n",
    "g.add((this.torayeff_exp_rcnn,FOAF.givenName, Literal('Agajan')))\n",
    "g.add((this.torayeff_exp_rcnn,FOAF.mbox, Literal('torayevagajan@gmail.com')))\n",
    "\n",
    "# RCNN model\n",
    "g.add((this.configuration_rcnn,RDF.type,mexcore.ExperimentConfiguration))\n",
    "g.add((this.configuration_rcnn,prov.used, this.model2))\n",
    "g.add((this.configuration_rcnn,prov.wasStartedBy, this.torayeff_exp_rcnn))\n",
    "\n",
    "g.add((this.test,RDF.type,mexcore.Test))\n",
    "g.add((this.test,RDFS.label,Literal('Test')))\n",
    "\n",
    "# hyperparameters\n",
    "g.add((this.hyperparameter_model_rcnn,RDF.type,mexalgo.HyperParameterCollection))\n",
    "g.add((this.hyperparameter_model_rcnn,RDFS.label,Literal('HyperParameterCollection')))\n",
    "g.add((this.hyperparameter_model_rcnn,prov.hadMember,this.hyerparameter1))\n",
    "g.add((this.hyperparameter_model_rcnn,prov.hadMember,this.hyerparameter2))\n",
    "g.add((this.hyperparameter_model_rcnn,prov.hadMember,this.hyerparameter3))\n",
    "g.add((this.hyperparameter_model_rcnn,prov.hadMember,this.hyerparameter4))\n",
    "g.add((this.hyperparameter_model_rcnn,prov.hadMember,this.hyerparameter5))\n",
    "g.add((this.hyperparameter_model_rcnn,prov.hadMember,this.hyerparameter6))\n",
    "g.add((this.hyperparameter_model_rcnn,prov.hadMember,this.hyerparameter7))\n",
    "\n",
    "g.add((this.hyerparameter1,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter1,RDFS.label, Literal('max_features')))\n",
    "g.add((this.hyerparameter1,DCTERMS.identifier, Literal('max_features')))\n",
    "g.add((this.hyerparameter1,prov.value, Literal('5000',datatype=XSD.integer)))\n",
    "\n",
    "g.add((this.hyerparameter2,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter2,RDFS.label, Literal('max_len')))\n",
    "g.add((this.hyerparameter2,DCTERMS.identifier, Literal('max_len')))\n",
    "g.add((this.hyerparameter2,prov.value, Literal('100',datatype=XSD.integer)))\n",
    "\n",
    "g.add((this.hyerparameter3,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter3,RDFS.label, Literal('embedding_size')))\n",
    "g.add((this.hyerparameter3,DCTERMS.identifier, Literal('embedding_size')))\n",
    "g.add((this.hyerparameter3,prov.value, Literal('256',datatype=XSD.integer)))\n",
    "\n",
    "g.add((this.hyerparameter4,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter4,RDFS.label, Literal('kernel_size')))\n",
    "g.add((this.hyerparameter4,DCTERMS.identifier, Literal('kernel_size')))\n",
    "g.add((this.hyerparameter4,prov.value, Literal('5',datatype=XSD.integer)))\n",
    "\n",
    "g.add((this.hyerparameter5,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter5,RDFS.label, Literal('filters')))\n",
    "g.add((this.hyerparameter5,DCTERMS.identifier, Literal('filters')))\n",
    "g.add((this.hyerparameter5,prov.value, Literal('64',datatype=XSD.integer)))\n",
    "\n",
    "g.add((this.hyerparameter6,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter6,RDFS.label, Literal('pool_size')))\n",
    "g.add((this.hyerparameter6,DCTERMS.identifier, Literal('pool_size')))\n",
    "g.add((this.hyerparameter6,prov.value, Literal('4',datatype=XSD.integer)))\n",
    "\n",
    "g.add((this.hyerparameter7,RDF.type,mexalgo.HyperParameter))\n",
    "g.add((this.hyerparameter7,RDFS.label, Literal('lstm_output_size')))\n",
    "g.add((this.hyerparameter7,DCTERMS.identifier, Literal('lstm_output_size')))\n",
    "g.add((this.hyerparameter7,prov.value, Literal('70',datatype=XSD.integer)))\n",
    "\n",
    "# Dataset\n",
    "g.add((this.dataset,RDF.type,mexcore.Dataset))\n",
    "g.add((this.dataset,RDFS.label,Literal('Sentiment-Classification')))\n",
    "g.add((this.dataset,DCTERMS.landingPage,Literal('https://github.com/SmartDataAnalytics/MA-INF-4222-NLP-Lab/blob/master/2018_SoSe/exercises/dataset_sentiment.csv')))\n",
    "\n",
    "# Execution\n",
    "g.add((this.execution1,RDF.type,mexcore.ExecutionOverall))\n",
    "g.add((this.execution1,prov.generated,this.performance_measures1))\n",
    "g.add((this.execution1,prov.used,this.test))\n",
    "g.add((this.execution1,prov.used,this.hyerparameter_model_rcnn))\n",
    "g.add((this.execution1,prov.used,this.model_rcnn))\n",
    "\n",
    "g.add((this.performance_measures1,RDF.type,mexcore.PerformanceMeasure))\n",
    "g.add((this.performance_measures1,mexperf.score,Literal('0.35',datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,mexperf.accuracy,Literal('0.85',datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,mexperf.pos_accuracy,Literal('0.51',datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,mexperf.neg_accuracy,Literal('0.94',datatype=XSD.float)))\n",
    "g.add((this.performance_measures1,prov.wasGeneratedBy,this.execution1))\n",
    "\n",
    "g.add((this.model1,RDF.type,mexalgo.Algorithm))\n",
    "g.add((this.model1,RDFS.label,Literal('Embedding')))\n",
    "g.add((this.model1,DCTERMS.identifier,Literal('Embedding')))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyperparameter1))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyperparameter2))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyperparameter3))\n",
    "\n",
    "g.add((this.model1,RDF.type,mexalgo.Algorithm))\n",
    "g.add((this.model1,RDFS.label,Literal('Convolution1D')))\n",
    "g.add((this.model1,DCTERMS.identifier,Literal('Convolution1D')))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyperparameter4))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyperparameter5))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyperparameter6))\n",
    "\n",
    "g.add((this.model1,RDF.type,mexalgo.Algorithm))\n",
    "g.add((this.model1,RDFS.label,Literal('LSTM')))\n",
    "g.add((this.model1,DCTERMS.identifier,Literal('LSTM')))\n",
    "g.add((this.model1,mexalgo.hasHyperParameter,this.hyperparameter7))\n",
    "\n",
    "with open('sentiment_exp.ttl','wb') as f:\n",
    "    f.write(g.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
